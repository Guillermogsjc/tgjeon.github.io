<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Translation on Taegyun Jeon</title>
    <link>https://tgjeon.github.io/tags/translation/</link>
    <description>Recent content in Translation on Taegyun Jeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Taegyun Jeon</copyright>
    <lastBuildDate>Tue, 23 Aug 2016 12:54:32 +0900</lastBuildDate>
    <atom:link href="https://tgjeon.github.io/tags/translation/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>RNNs in Tensorflow, A Practical Guide and Undocumented Features</title>
      <link>https://tgjeon.github.io/post/rnns-in-tensorflow/</link>
      <pubDate>Tue, 23 Aug 2016 12:54:32 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnns-in-tensorflow/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/&#34;&gt;Original post&lt;/a&gt; is written by Denny Britz (Google Brain team).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 위 내용을 한글로 정리한 내용입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이전 &lt;a href=&#34;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&#34;&gt;튜토리얼&lt;/a&gt;에서, Recurrent Neural Networks (RNNs)에 대한 이론들에 대해서 살펴보고, 간단한 RNN을 기초부터 만들어보는 과정을 진행했습니다. 이 과정들은 유용했지만, 현업에선 RNNs에 대한 고수준의 기초요소들을 제공하는 Tensorflow와 같이 라이브러리를 사용합니다.&lt;/p&gt;

&lt;p&gt;RNNs을 함수 호출해서 사용하는 것처럼 쉽게 쓰면 좋겠지만, 현실은 만만치 않습니다. 이번 포스트에서는 Tensorflow를 이용하여 RNNs을 실질적으로 동작시켜보고, 특히 공식 사이트에서 문서화 되지 않은 기능들에 대해 다뤄보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;본 포스트는 Jupyer 노트북이 포함된 Github 저장소에 아래와 같은 예제들을 다루고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 사용하기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching과 Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/bidirectional_rnn.ipynb&#34;&gt;Bidirectional Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/rnn_cell_wrappers.py.ipynb&#34;&gt;RNN Cells과 Cell Wrappers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/loss_masking.py.ipynb&#34;&gt;Masking the Loss&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;데이터-전처리-tf-sequenceexample-사용하기&#34;&gt;데이터 전처리: tf.SequenceExample 사용하기&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNNs은 순차적인 데이터를 사용하며, 이 순차적인 데이터는 입력과 출력을 여러 시간 스텝으로 구성되어 있습니다. Tensorflow는 순차적 데이터: &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto&#34;&gt;tf.SequenceExample&lt;/a&gt; 를 다루기 위해 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;프로토콜 버퍼&lt;/a&gt;가 정의되어 있습니다.&lt;/p&gt;

&lt;p&gt;사용자는 Python/Numpy 배열로부터 직접 데이터를 불러올 수 있습니다. 하지만, &lt;code&gt;tf.SequenceExample&lt;/code&gt;가 더 관심 대상이므로 이것을 사용해보도록 합시다. 이 자료 구조는 비순차적 특징 (non-sequential features)은 &lt;code&gt;&amp;quot;context&amp;quot;&lt;/code&gt;로, 순차적 특징 (sequential features)은 &lt;code&gt;&amp;quot;feature_lists&amp;quot;&lt;/code&gt;로 구성됩니다. 장황하긴 하지만, 이것이 주는 장점은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;쉬운 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#distributed-tensorflow&#34;&gt;분산 학습&lt;/a&gt;&lt;/strong&gt;:&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://tgjeon.github.io/post/rnn_rnn/</link>
      <pubDate>Tue, 05 Jul 2016 05:33:52 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_rnn/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-2-recurrent-neural-networks-rnns&#34;&gt;10.2 Recurrent Neural Networks (RNNs)&lt;/h3&gt;

&lt;p&gt;앞선 &lt;a href=&#34;https://tgjeon.github.io/post/rnn_unfolding_computational_graph/&#34;&gt;포스트&lt;/a&gt;에서 설명한 그래프 풀기 (graph unrolling)과 파라미터 공유 (parameter sharing)을 통해 다양한 형태의 recurrent neural networks를 디자인 할 수 있다.&lt;/p&gt;

&lt;p&gt;Recurrent Neural Networks의 중요한 디자인 패턴들은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;그림 10.3

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (h^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.4

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden-Output (hidden/output unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (o^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.5

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (최종 시점 $\tau$에만), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h^{\tau}, o^{\tau}), (o^\tau, L^\tau), (L^\tau, y^\tau)$ (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;처음 소개된 그림 10.3과 같은 형태는, recurrent neural networks의 가장 대표적인 형태이며, 이번 내용에서 가장 많이 설명될 것이다. 이와 같은 형태는 Turing machine과 같은 계산 과정을 통해 수행된다고 생각하면 된다. 시점 $t$의 갯수 (점근적 선형으로 증가하는) 만큼의 입력을 받아 해당 시점 이후의 출력을 가진다. 이는 근사치가 아닌 정확한 계산 결과이며 이산값으로 나타낸다.&lt;/p&gt;

&lt;p&gt;그림 10.3에서 동작하는 forward propagation 수식을 살펴보자. 개념적인 이야기를 다루고 있기 때문에, activation function, loss function, output 형태를 언급하지 않고 있다. 따라서, activation function은 $\tanh$로 두고 output은 discrete 값을 가정한다. 그리고 RNN 모델은 단어나 문자를 예측하는데 사용된다고 가정하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;output $o$는 각 이산값에 대해 정규화되지 않은 확률 분포로 나타낸다.&lt;/li&gt;
&lt;li&gt;최종 예측값은 $\hat{y}$는 출력 $o$에 대해 softmax()를 적용하여 정규화된 확률 값을 가진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forward propagation은 다음과 같이 동작한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Initial state: $h^{(0)}$로 부터 시작.&lt;/li&gt;
&lt;li&gt;Input-to-hidden ($U$)과 hidden-to-hidden ($W$): $a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$&lt;/li&gt;
&lt;li&gt;Activation: $h^{(t)} = \tanh(a^{(t)})$&lt;/li&gt;
&lt;li&gt;hidden-to-output ($V$): $o^{(t)} = c + Vh^{(t)}$&lt;/li&gt;
&lt;li&gt;Normailized discrete output: ${\hat{y}}^{(t)} = softmax(o^{(t)})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모델은 입력 sequence와 출력 sequence의 길이가 동일하다. 전체 입,출력 sequence에 대한 loss는 각 시점 (time steps)마다의 loss를 모두 더한 것과 같다.&lt;/p&gt;

&lt;p&gt;$ L(${ $x^{(1)}, &amp;hellip;, x^{(\tau)} $}, { $y{(1)}, &amp;hellip;, y^{(\tau)} $}$)$&lt;/p&gt;

&lt;p&gt;$= \sum _{t}{L^{(t)}} $&lt;/p&gt;

&lt;p&gt;$= -\sum _{t}{\log{p}} _{model} (y^{(t)} | ${ $x^{(1)}, &amp;hellip;, x^{(t)} $}$)$&lt;/p&gt;

&lt;p&gt;$L^{(t)} $가 입력 $x^{(1)}, &amp;hellip;, x^{(t)}$이 주어졌을 때, 출력 $y^{(t)}$에 대한 negative log-likelihood라고 하자.
gradient를 계산하는 과정은 각 시점 (time steps)에 대해 수행된다. 수행 시간은 $O(\tau)$이며, 병렬처리가 불가능하다.
이 모델은 강력하지만 학습 과정에서 많은 계산량을 요구한다. 이를 &lt;em&gt;back-propagation through time&lt;/em&gt; 혹은 &lt;em&gt;BPTT&lt;/em&gt; 라고 한다.&lt;/p&gt;

&lt;h3 id=&#34;10-2-1-teacher-forcing-and-networks-with-output-recurrence&#34;&gt;10.2.1 Teacher Forcing and Networks with Output Recurrence&lt;/h3&gt;

&lt;p&gt;그림 10.4에서 보여주고 있는 RNN모델은 hidden-to-hidden 연결성이 부족하기 때문에 강력하지 않다. hidden-to-hidden 연결이 없기 때문에, output 유닛이 과거 네트워크의 모든 정보를 가지고 미래를 예측해야한다. 그래서, output 유닛은 명백하게 학습 데이터의 타겟에 대해 학습된다. 사용자는 과거 모든 입력의 기록을 모아둘 필요가 없어진다.&lt;/p&gt;

&lt;p&gt;hidden-to-hidden 연결을 제거함으로 얻는 이득은, 시점 $t$에서 예측하는 데 필요한 loss의 계산이 모든 시점 $t$에 대한 관계성이 없어진다. 따라서 학습 단계는 병렬처리 가능하며, 각 시점 $t$에서의 gradient 계산은 독립적으로 수행 가능하다.&lt;/p&gt;

&lt;p&gt;output에서 바로 모델이 학습 하는 경우를 teacher forcing 이라고 한다. 이는 maximum likelihood criterion을 따르며, ground truth $\hat(y)^{(t)}$가 $t+1$ 시점의 입력으로 사용된다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;두 시점의 sequence를 예를 들어보면, conditional maximum likelihood criterion은 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \log{p} (y^{(1)}, y^{(2)} | x^{(1)}, x^{(2)})$&lt;/p&gt;

&lt;p&gt;$ = \log{p} (y^{(2)} | y^{(1)}, x^{(1)}, x^{(2)})  +  \log{p} (y^{(1)} | x^{(1)}, x^{(2)}) $&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unfolding Computational Graphs</title>
      <link>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</link>
      <pubDate>Thu, 02 Jun 2016 00:59:05 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-1-unfolding-computational-graphs&#34;&gt;10.1 Unfolding Computational Graphs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Classical Dynamic System&lt;/strong&gt;:
$ S^{ (t) }=f(s^{ (t-1) };\theta ) $, 여기서 $s^{(t)}$ 는 시스템의 상태를 나타낸다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dynamical system driven by an external signal&lt;/strong&gt; $ x^{(t)} $:
$ S^{ (t) }=f(s^{ (t-1) }, x^{(t)} ;\theta ) $&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) 은 다양한 방법으로 만들수 있다. 대부분은 feedforward neural network로 간주되며, recurrence (재귀표현)를 포함하고 있다면 Recurrent Neural Networks (RNN) 이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;앞서 나온 &lt;strong&gt;Dynamical System&lt;/strong&gt; 식을 이용해, 다음과 같이 유사한 형태의 식으로 RNN의 hidden unit을 정의한다.
$$ h^{(t)} = f(h^{ (t-1) }, x^{(t)} ;\theta ) $$&lt;/p&gt;

&lt;p&gt;예를 들어, RNN이 과거 데이터를 학습하고, 미래를 예측하는 일을 수행한다고 하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;입력: $ x^{(t)}$ (시점 $t$ 까지의 입력)&lt;/li&gt;
&lt;li&gt;종합: $ h^{(t)}$ (정보 손실이 있는 종합된 내용)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 과정을 통해 과거 정보에서 선택적으로 필요한 정보만 유지하여 종합한다. 예를 들어, RNN이 통계적 언어 모델링을 통해, 과거의 단어들을 바탕으로 다음에 나올 단어를 예측한다. 이를 위해, 시점 (time step) $t$ 까지 모든 입력을 다 기억할 필요는 없다. 일정한 정보만으로도 문장의 나머지 단어들을 예측하기에 충분하다.&lt;/p&gt;

&lt;p&gt;RNN을 그림으로 묘사하는 두가지 방법이 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph&lt;/code&gt;: 모든 기능을 하나의 노드로만 표현.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;: 각 기능들이 각각의 노드로 표현. Unfolded 표현은 sequence 길이와 연관된 크기를 가진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unfolding 과정은 다음과 같은 장점을 지닌다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sequence 길이와 상관없이, 학습된 모델은 항상 같은 입력 크기를 가진다.&lt;/li&gt;
&lt;li&gt;같은 파라미터를 사용하는 전이 함수 (transition function) $f$ 를 사용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두가지 요인 때문에, 각 시점마다 $g^{(t)}$ 를 개별적으로 학습시키지 않아도 된다. 같은 파리미터가 공유되기 때문에, 단일 모델 $f$ 가 모든 sequence 길이와 모든 시점에서 동작한다.&lt;/p&gt;

&lt;p&gt;단일화, 공유되는 모델 학습은 일반화를 가능하게 한다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;학습 데이터상의 sequence 길이에 무관하다.&lt;/li&gt;
&lt;li&gt;적은 학습 데이터로도 예측이 가능하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두가지 RNN 표현법은 다음과 같이 각자의 용도가 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph (recurrent graph)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;간단명료하다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;각 단계에서 계산 수행을 분명하게 기술한다.&lt;/li&gt;
&lt;li&gt;진행 방향에 따라 아이디어를 묘사하기 쉽다.&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Forward): output과 loss의 계산&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Backward): gradient 계산&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning in a Nutshell: Core Concepts</title>
      <link>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</link>
      <pubDate>Sat, 23 Apr 2016 16:58:51 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Original post&lt;/a&gt; is written by Tim Dettmers&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall&#34;&gt;Parallel ForAll&lt;/a&gt; 에 작성하는 시리즈 중 첫 글이며, &lt;a href=&#34;https://developer.nvidia.com/deep-learning&#34;&gt;딥 러닝&lt;/a&gt;에 대해 직관적이고 가볍게 소개하고자 한다. 본 포스트는 딥 러닝의 가장 중요한 개념을 다루고 있으며, 수학적 이론 지식보다 기본적인 개념의 전달을 목적으로 한다. 수식과 함께라면 더 깊은 이해가 가능하겠지만, 이 포스트는 비유와 그림을 통해 더욱 이해하기 쉬운 직관적인 개요를 전달하고자 한다.
이 글들은 단어사전식으로 작성되어 딥러닝 개념을 위한 참고자료로 사용 될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Part 1&lt;/a&gt;에서는 딥 러닝의 중요한 개념에 대해서 소개한다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training&#34;&gt;Part 2&lt;/a&gt;에서는 딥 러닝의 역사적 배경과 학습 과정, 알고리즘, 실용적인 기법 등을 살펴본다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-sequence-learning&#34;&gt;Part 3&lt;/a&gt;에서는 자연어 번역을 위한 sequence learning 에 대해 알아본다. recurrent neural networks, LSTMs, encoder-decoder system을 포함한다.&lt;/p&gt;

&lt;h2 id=&#34;core-concepts-핵심-개념&#34;&gt;Core Concepts (핵심 개념)&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;machine-learning-기계-학습&#34;&gt;Machine Learning (기계 학습)&lt;/h3&gt;

&lt;p&gt;기계 학습을 통해 우리는 (1) 데이터를 획득하여, (2) 데이터를 통해 모델을 학습하고, (3) 학습된 모델을 이용하여, 새로운 데이터에 대해 예측한다. 모델을 &lt;a href=&#34;http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training#training&#34;&gt;학습&lt;/a&gt;하는 과정은 새롭고, 익숙치 않은 자료를 하나씩 살펴보고 배움을 얻는 과정과도 같다. 각 단계마다, 모델은 예측을 하고, 얼마나 정확히 예측하였는지에 대해 피드백을 받는다. 이 피드백은 정답으로부터 얼만큼 차이가 나는지 등과 같은 방법을 통해 측정 가능한 오류(error)를 통해, 예측을 더 정확하게 하는데 사용된다.&lt;/p&gt;

&lt;p&gt;학습과정은 종종 파라미터 공간 (parameter space)에서 후진-전진이 반복는 게임이다: 만약 당신이 좋은 예측 결과를 얻기 위해 모델의 파라미터를 수정한다면, 이전에 제대로 예측했던 것도 수정 이후, 틀리게 예측될 수도 있다. 우수한 예측 성능을 가진 모델을 학습한다는 것은 많은 반복 작업이 필요할 것이다. 이런 반복적인 예측-수정의 과정은 예측 결과가 더 이상 발전이 없을 때 까지 반복한다.&lt;/p&gt;

&lt;h3 id=&#34;feature-engineering-특징-공학&#34;&gt;Feature Engineering (특징 공학)&lt;/h3&gt;

&lt;p&gt;특징 공학은 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/#machine-learning&#34;&gt;기계 학습&lt;/a&gt; 모델로 하여금 데이터들로 부터 클래스들을 쉽게 구분 할 수 있도록 도와주는 유용한 패턴을 추출 하는 것이다. 예를 들어,사진으로 부터 땅과 물고기를 구분하는 것을 초록색과 푸른색 픽셀의 수를 이용한다고 하자. 이런 특징은 기계 학습 모델에 도움이 된다. 좋은 분류를 위해 클래스의 갯수가 제한되어 있기때문에 좋은 분류가 가능하다.&lt;/p&gt;

&lt;p&gt;특징 공학은 대부분의 예측 분야에서 좋은 성능을 얻기위해 요구되는 가장 중요한 기술이다. 하지만, 다른 데이터 셋과 다른 종류의 데이터들은 각자 다른 특징 공학 기법이 필요하기에, 최고의 특징 공학 기술을 습득하고 마스터하기엔 어렵다. 특징 공학은 과학이라기 보다 예술의 경지에 가깝다. 특정 데이터 셋에서 추출된 특징은 종종 다른 데이터 셋에서는 적용되지 않는다. (위 예제에서 계속하여, 다음 사진이 오직 육지 동물만 포함하는 경우). 특징 공학이 어렵다는 점과 많은 노력이 요구되는 점이 &lt;strong&gt;자동으로 특징을 학습할 수 있는 알고리즘&lt;/strong&gt;을 찾게 되는 가장 큰 이유이다.&lt;/p&gt;

&lt;p&gt;물체 인식이나 음성 인식과 같은 분야의 영역이 특징 학습을 통해 자동화되고 있지만, 특징 공학은 &lt;a href=&#34;http://blog.kaggle.com/2014/08/01/learning-from-the-best/&#34;&gt;kaggle 기계 학습 대회의 어려운 여러 분야에서 가장 효율적인 방법&lt;/a&gt;으로  여전히 지속 될 것이다.&lt;/p&gt;

&lt;h3 id=&#34;feature-learning-특징-학습&#34;&gt;Feature Learning (특징 학습)&lt;/h3&gt;

&lt;p&gt;특징 학습 알고리즘은 서로 다른 범주(클래스)의 분류를 위한 가장 중요하며, 공통적으로 나타나는 패턴을 찾는다. 그리고 특징을 자동으로 추출하여 분류나 회귀 문제에 적용된다. 특징 학습은 특징 공학처럼 알고리즘을 통해 자동으로 수행되는 것 처럼 생각된다. 딥러닝에서는 convolutional layer가 예외적으로 이미지에서 좋은 특징을 찾는데 탁월한 능력을 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/11/hierarchical_features.png&#34; alt=&#34;&#34; /&gt;
Figure 1: 딥 러닝 알고리즘으로 부터 학습된 계층형 특징들.&lt;/p&gt;

&lt;h4 id=&#34;deep-learning-딥-러닝&#34;&gt;Deep Learning (딥 러닝)&lt;/h4&gt;

&lt;h3 id=&#34;fundamental-concepts-기본-개념&#34;&gt;Fundamental Concepts (기본 개념)&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;logistic-regression&#34;&gt;Logistic Regression ()&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neural-network-인공-신경망&#34;&gt;Artificial Neural Network (인공 신경망)&lt;/h4&gt;

&lt;h4 id=&#34;unit&#34;&gt;Unit&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neuron&#34;&gt;Artificial Neuron&lt;/h4&gt;

&lt;h4 id=&#34;activation-function&#34;&gt;Activation Function&lt;/h4&gt;

&lt;h4 id=&#34;layer&#34;&gt;Layer&lt;/h4&gt;

&lt;h3 id=&#34;convolutional-deep-learning&#34;&gt;Convolutional Deep Learning&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;convolution&#34;&gt;Convolution&lt;/h4&gt;

&lt;h4 id=&#34;pooling-subsampling&#34;&gt;Pooling / Subsampling&lt;/h4&gt;

&lt;h4 id=&#34;convolutional-neural-network-cnn&#34;&gt;Convolutional Neural Network (CNN)&lt;/h4&gt;

&lt;h4 id=&#34;inception&#34;&gt;Inception&lt;/h4&gt;

&lt;h3 id=&#34;conclusion-to-part-1&#34;&gt;Conclusion to Part 1&lt;/h3&gt;

&lt;hr /&gt;
</description>
    </item>
    
  </channel>
</rss>