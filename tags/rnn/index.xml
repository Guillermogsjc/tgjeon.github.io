<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rnn on Taegyun Jeon</title>
    <link>https://tgjeon.github.io/tags/rnn/</link>
    <description>Recent content in Rnn on Taegyun Jeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Taegyun Jeon</copyright>
    <lastBuildDate>Tue, 23 Aug 2016 12:54:32 +0900</lastBuildDate>
    <atom:link href="https://tgjeon.github.io/tags/rnn/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>RNNs in Tensorflow, A Practical Guide and Undocumented Features</title>
      <link>https://tgjeon.github.io/post/rnns-in-tensorflow/</link>
      <pubDate>Tue, 23 Aug 2016 12:54:32 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnns-in-tensorflow/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/&#34;&gt;Original post&lt;/a&gt; is written by Denny Britz (Google Brain team).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 위 내용을 한글로 정리한 내용입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이전 &lt;a href=&#34;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&#34;&gt;튜토리얼&lt;/a&gt;에서, Recurrent Neural Networks (RNNs)에 대한 이론들에 대해서 살펴보고, 간단한 RNN을 기초부터 만들어보는 과정을 진행했습니다. 이 과정들은 유용했지만, 현업에선 RNNs에 대한 고수준의 기초요소들을 제공하는 Tensorflow와 같이 라이브러리를 사용합니다.&lt;/p&gt;

&lt;p&gt;RNNs을 함수 호출해서 사용하는 것처럼 쉽게 쓰면 좋겠지만, 현실은 만만치 않습니다. 이번 포스트에서는 Tensorflow를 이용하여 RNNs을 실질적으로 동작시켜보고, 특히 공식 사이트에서 문서화 되지 않은 기능들에 대해 다뤄보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;본 포스트는 Jupyer 노트북이 포함된 Github 저장소에 아래와 같은 예제들을 다루고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 사용하기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching과 Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/bidirectional_rnn.ipynb&#34;&gt;Bidirectional Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/rnn_cell_wrappers.py.ipynb&#34;&gt;RNN Cells과 Cell Wrappers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/loss_masking.py.ipynb&#34;&gt;Masking the Loss&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;데이터-전처리-tf-sequenceexample-사용하기&#34;&gt;데이터 전처리: tf.SequenceExample 사용하기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RNNs은 순차적인 데이터를 사용하며, 이 순차적인 데이터는 입력과 출력을 여러 시간 스텝으로 구성되어 있습니다. Tensorflow는 순차적 데이터: &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto&#34;&gt;tf.SequenceExample&lt;/a&gt; 를 다루기 위해 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;프로토콜 버퍼&lt;/a&gt;가 정의되어 있습니다.&lt;/p&gt;

&lt;p&gt;사용자는 Python/Numpy 배열로부터 직접 데이터를 불러올 수 있습니다. 하지만, &lt;code&gt;tf.SequenceExample&lt;/code&gt;가 더 관심 대상이므로 이것을 사용해보도록 합시다. 이 자료 구조는 비순차적 특징 (non-sequential features)은 &lt;code&gt;&amp;quot;context&amp;quot;&lt;/code&gt;로, 순차적 특징 (sequential features)은 &lt;code&gt;&amp;quot;feature_lists&amp;quot;&lt;/code&gt;로 구성됩니다. 장황하긴 하지만, 이것이 주는 장점은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;쉬운 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#distributed-tensorflow&#34;&gt;분산 학습&lt;/a&gt;&lt;/strong&gt;: 데이터를 여러개의 SequenceExamples을 포함하는 &lt;code&gt;TFRecord&lt;/code&gt; 파일들로 나누고, Tensorflow에 탑재된 분산 학습 기능을 이용합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;재사용성 (Reusability)&lt;/strong&gt;: 다른 사용자들도 본인이 만든 모델을 가져다가 자신들의 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 형태로 바꿔서 사용할 수 있습니다. 모델 코드 부분을 수정할 필요가 없습니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tensorflow의 데이터 불러오기 파이프라인 함수 사용&lt;/strong&gt;: &lt;code&gt;tf.parse_single_sequence_example&lt;/code&gt;과 같이 사용 가능합니다. &lt;code&gt;tf.learn&lt;/code&gt;과 같은 라이브러리 역시 데이터 입력을 프로토콜 버퍼 포맷으로 입력될 것을 예상하여, 간편한 함수를 지원합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;데이터 전처리와 모델 코드의 분리&lt;/strong&gt;: &lt;code&gt;tf.SequenceExample&lt;/code&gt;을 이용하게 되면, 사용자로 하여금 데이터 전처리와 Tensorflow 모델 코드 부분을 분리하도록 합니다. 이것은 소스코드 작성에 매우 유익한 부분이며, 입력 데이터가 어떤 형태로 들어올지 가정하지 않아도 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;실제로, 사용자가 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 포맷으로 변환하는 작은 스크립트를 작성하고, 그다음 하나 혹은 여러개의 &lt;code&gt;TFRecord&lt;/code&gt; 파일을 작성합니다. 이 &lt;code&gt;TFRecord&lt;/code&gt;파일은 Tensorflow가 파싱 (parsing)하게 되고, 사용자 모델의 입력이 됩니다:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;사용자의 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 포맷으로 변환합니다.&lt;/li&gt;
&lt;li&gt;serialized 데이터를 &lt;code&gt;TFRecord&lt;/code&gt;로 하나 혹은 여러개 파일로 작성합니다.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#TFRecordReader&#34;&gt;&lt;code&gt;tf.TFRecordReader&lt;/code&gt;&lt;/a&gt;를 이용하여 examples을 파일로부터 읽어옵니다.&lt;/li&gt;
&lt;li&gt;각 example을 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/python/ops/parsing_ops.py&#34;&gt;&lt;code&gt;tf.parse_single_sequence_example&lt;/code&gt;&lt;/a&gt;를 이용해 파싱합니다. (아직 공식 문서화되지 않은 기능입니다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sequences = [[1, 2, 3], [4, 5, 1], [1, 2]]
label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]
 
def make_example(sequence, labels):
    # 결과값은 example입니다.
    ex = tf.train.SequenceExample()
    # non-sequential feature 부분입니다. (데이터를 설명하는 정보)
    sequence_length = len(sequence)
    ex.context.feature[&amp;quot;length&amp;quot;].int64_list.value.append(sequence_length)
    # sequential features 부분인 feature_lists 부분입니다. (실제 데이터)
    fl_tokens = ex.feature_lists.feature_list[&amp;quot;tokens&amp;quot;]
    fl_labels = ex.feature_lists.feature_list[&amp;quot;labels&amp;quot;]
    for token, label in zip(sequence, labels):
        fl_tokens.feature.add().int64_list.value.append(token)
        fl_labels.feature.add().int64_list.value.append(label)
    return ex
 
# 모든 examples을 하나의 TFRecord파일로 작성합니다.
with tempfile.NamedTemporaryFile() as fp:
    writer = tf.python_io.TFRecordWriter(fp.name)
    for sequence, label_sequence in zip(sequences, label_sequences):
        ex = make_example(sequence, label_sequence)
        writer.write(ex.SerializeToString())
    writer.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고, example을 파싱하여 사용합니다:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 하나의 serialized example입니다.
# (TFRecordReader를 이용하여 하나의 example을 읽어올 수 있습니다.)
ex = make_example([1, 2, 3], [0, 1, 0]).SerializeToString()
 
# example을 파싱하는 방식을 정의합니다. (이름과 데이터 타입)
context_features = {
    &amp;quot;length&amp;quot;: tf.FixedLenFeature([], dtype=tf.int64)
}
sequence_features = {
    &amp;quot;tokens&amp;quot;: tf.FixedLenSequenceFeature([], dtype=tf.int64),
    &amp;quot;labels&amp;quot;: tf.FixedLenSequenceFeature([], dtype=tf.int64)
}
 
# example로 부터 파싱합니다.
context_parsed, sequence_parsed = tf.parse_single_sequence_example(
    serialized=ex,
    context_features=context_features,
    sequence_features=sequence_features
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;batching과-데이터-padding&#34;&gt;Batching과 데이터 Padding&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching and Padding 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow의 RNN 함수는 $[B, T, &amp;hellip;]$ 형태의 tensor를 입력으로 기대합니다. 여기서 $B$는 배치 사이즈, $T$는 각 입력의 시간 길이를 의미합니다. (예. 한 문장의 단어 수). 그리고 마지막 dimension은 사용자의 데이터와 관련있습니다. 문제를 눈치채셨나요? 보편적으로, 하나의 배치에 포함된 모드 sequence들이 길이 $T$와 같지 않다는 것입니다. 하지만 RNN 모델에 입력으로 집어넣어주기 위해서는 길이를 맞춰줘야 합니다. 보통은 padding을 통해 해결합니다: 각 example에 0을 채워 넣어서 sequence의 길이를 같게 맞춰줍니다.&lt;/p&gt;

&lt;p&gt;만약, 사용자의 sequence중 하나의 길이가 1000이라고 합시다. 하지만 sequences의 평균 길이가 20이라고 한다면 어떨까요? 만약 모든 example에 대해 길이 1000개에 맞춰서 padding을 하게 되면, 엄청난 공간 (뿐만 아니라 계산 시간)의 낭비가 발생합니다. 바로 여기서 batch padding이 필요합니다. 만약 사용자가 32개의 배치들을 만들었다면, 단지 각 배치에 있는 examples을 같은 크기 (해당 배치의 최대 길이의 example 크기에 맞춰서)로만 padding 시키면 되는 것입니다. 이 방식대로라면, 정말 긴 example은 오직 하나의 배치에만 영향을 미칩니다. 다른 모든 배치의 example 데이터들은 영향에서 벗어날 수 있습니다.&lt;/p&gt;

&lt;p&gt;실제로 다루기엔 지저분해보이지만, 다행스럽게도 Tensorflow에는 batch padding 기능을 포함하고 있습니다. 만약 사용자가 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#batch&#34;&gt;&lt;code&gt;tf.train.batch&lt;/code&gt;&lt;/a&gt;를 호출할 때 &lt;code&gt;dynamic_pad=True&lt;/code&gt;로 설정한다면, 반환되는 batch 결과값들은 자동적으로 0이 padding됩니다. 편리하네요! lower-level 옵션은 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#PaddingFIFOQueue&#34;&gt;&lt;code&gt;tf.PaddingFIFOQueue&lt;/code&gt;&lt;/a&gt;를 사용하는 것입니다.&lt;/p&gt;

&lt;h4 id=&#34;side-note-단어-vocabulary-종류-class-를-사용할때는-0으로-padding-하는-것을-주의해서-쓰세요&#34;&gt;Side note: 단어(Vocabulary)/종류(class)를 사용할때는 0으로 padding 하는 것을 주의해서 쓰세요!&lt;/h4&gt;

&lt;p&gt;만약 사용자가 분류 (classification) 문제를 다루고 있고, 입력 tensor가 class IDs (0, 1, 2, &amp;hellip;)를 포함한다면, padding을 사용할때 주의해야 합니다. tensor를 0으로 padding 한다면, 0-padding과 &amp;ldquo;class 0&amp;rdquo;과의 차이점을 구분할 수 없는 경우가 생깁니다. 사용자 모델이 다루고자 하는 문제에 따라 달라지겠지만, 이 이슈에 대해서 안전하고 싶다면 &amp;ldquo;class 0&amp;rdquo; 대신 &amp;ldquo;class 1&amp;rdquo;로 부터 시작하도록 사용해보세요. (이 예제가 masking the loss function 부분에서 문제를 발생시킵니다. 자세한 내용은 아래에서 설명하도록 하겠습니다.)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# [0, 1, 2, 3, 4 ,...]
x = tf.range(1, 10, name=&amp;quot;x&amp;quot;)
 
# A queue that outputs 0,1,2,3,...
range_q = tf.train.range_input_producer(limit=5, shuffle=False)
slice_end = range_q.dequeue()
 
# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....
y = tf.slice(x, [0], [slice_end], name=&amp;quot;y&amp;quot;)
 
# Batch the variable length tensor with dynamic padding
batched_data = tf.train.batch(
    tensors=[y],
    batch_size=5,
    dynamic_pad=True,
    name=&amp;quot;y_batch&amp;quot;
)
 
# Run the graph
# tf.contrib.learn takes care of starting the queues for us
res = tf.contrib.learn.run_n({&amp;quot;y&amp;quot;: batched_data}, n=1, feed_dict=None)
 
# Print the result
print(&amp;quot;Batch shape: {}&amp;quot;.format(res[0][&amp;quot;y&amp;quot;].shape))
print(res[0][&amp;quot;y&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다음과 같은 결과를 나타냅니다:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Batch shape: (5, 4)
[[0 0 0 0]
 [1 0 0 0]
 [1 2 0 0]
 [1 2 3 0]
 [1 2 3 4]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고 &lt;code&gt;PaddingFIFOQueue&lt;/code&gt;를 사용한 결과도 동일합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ... Same as above
 
# Creating a new queue
padding_q = tf.PaddingFIFOQueue(
    capacity=10,
    dtypes=tf.int32,
    shapes=[[None]])
 
# Enqueue the examples
enqueue_op = padding_q.enqueue([y])
 
# Add the queue runner to the graph
qr = tf.train.QueueRunner(padding_q, [enqueue_op])
tf.train.add_queue_runner(qr)
 
# Dequeue padded data
batched_data = padding_q.dequeue_many(5)
 
# ... Same as above
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnn과-dynamic-rnn&#34;&gt;RNN과 Dynamic_RNN&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;DYNAMIC_RNN 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow는 두가지 종류의 RNNs을 제공하고 있습니다: &lt;code&gt;tf.nn.rnn&lt;/code&gt;과 &lt;code&gt;tf.nn.dynamic_rnn&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://tgjeon.github.io/post/rnn_rnn/</link>
      <pubDate>Tue, 05 Jul 2016 05:33:52 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_rnn/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-2-recurrent-neural-networks-rnns&#34;&gt;10.2 Recurrent Neural Networks (RNNs)&lt;/h3&gt;

&lt;p&gt;앞선 &lt;a href=&#34;https://tgjeon.github.io/post/rnn_unfolding_computational_graph/&#34;&gt;포스트&lt;/a&gt;에서 설명한 그래프 풀기 (graph unrolling)과 파라미터 공유 (parameter sharing)을 통해 다양한 형태의 recurrent neural networks를 디자인 할 수 있다.&lt;/p&gt;

&lt;p&gt;Recurrent Neural Networks의 중요한 디자인 패턴들은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;그림 10.3

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (h^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.4

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden-Output (hidden/output unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (o^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.5

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (최종 시점 $\tau$에만), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h^{\tau}, o^{\tau}), (o^\tau, L^\tau), (L^\tau, y^\tau)$ (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;처음 소개된 그림 10.3과 같은 형태는, recurrent neural networks의 가장 대표적인 형태이며, 이번 내용에서 가장 많이 설명될 것이다. 이와 같은 형태는 Turing machine과 같은 계산 과정을 통해 수행된다고 생각하면 된다. 시점 $t$의 갯수 (점근적 선형으로 증가하는) 만큼의 입력을 받아 해당 시점 이후의 출력을 가진다. 이는 근사치가 아닌 정확한 계산 결과이며 이산값으로 나타낸다.&lt;/p&gt;

&lt;p&gt;그림 10.3에서 동작하는 forward propagation 수식을 살펴보자. 개념적인 이야기를 다루고 있기 때문에, activation function, loss function, output 형태를 언급하지 않고 있다. 따라서, activation function은 $\tanh$로 두고 output은 discrete 값을 가정한다. 그리고 RNN 모델은 단어나 문자를 예측하는데 사용된다고 가정하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;output $o$는 각 이산값에 대해 정규화되지 않은 확률 분포로 나타낸다.&lt;/li&gt;
&lt;li&gt;최종 예측값은 $\hat{y}$는 출력 $o$에 대해 softmax()를 적용하여 정규화된 확률 값을 가진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forward propagation은 다음과 같이 동작한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Initial state: $h^{(0)}$로 부터 시작.&lt;/li&gt;
&lt;li&gt;Input-to-hidden ($U$)과 hidden-to-hidden ($W$): $a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$&lt;/li&gt;
&lt;li&gt;Activation: $h^{(t)} = \tanh(a^{(t)})$&lt;/li&gt;
&lt;li&gt;hidden-to-output ($V$): $o^{(t)} = c + Vh^{(t)}$&lt;/li&gt;
&lt;li&gt;Normailized discrete output: ${\hat{y}}^{(t)} = softmax(o^{(t)})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모델은 입력 sequence와 출력 sequence의 길이가 동일하다. 전체 입,출력 sequence에 대한 loss는 각 시점 (time steps)마다의 loss를 모두 더한 것과 같다.&lt;/p&gt;

&lt;p&gt;$ L(${ $x^{(1)}, &amp;hellip;, x^{(\tau)} $}, { $y{(1)}, &amp;hellip;, y^{(\tau)} $}$)$&lt;/p&gt;

&lt;p&gt;$= \sum _{t}{L^{(t)}} $&lt;/p&gt;

&lt;p&gt;$= -\sum _{t}{\log{p}} _{model} (y^{(t)} | ${ $x^{(1)}, &amp;hellip;, x^{(t)} $}$)$&lt;/p&gt;

&lt;p&gt;$L^{(t)} $가 입력 $x^{(1)}, &amp;hellip;, x^{(t)}$이 주어졌을 때, 출력 $y^{(t)}$에 대한 negative log-likelihood라고 하자.
gradient를 계산하는 과정은 각 시점 (time steps)에 대해 수행된다. 수행 시간은 $O(\tau)$이며, 병렬처리가 불가능하다.
이 모델은 강력하지만 학습 과정에서 많은 계산량을 요구한다. 이를 &lt;em&gt;back-propagation through time&lt;/em&gt; 혹은 &lt;em&gt;BPTT&lt;/em&gt; 라고 한다.&lt;/p&gt;

&lt;h3 id=&#34;10-2-1-teacher-forcing-and-networks-with-output-recurrence&#34;&gt;10.2.1 Teacher Forcing and Networks with Output Recurrence&lt;/h3&gt;

&lt;p&gt;그림 10.4에서 보여주고 있는 RNN모델은 hidden-to-hidden 연결성이 부족하기 때문에 강력하지 않다. hidden-to-hidden 연결이 없기 때문에, output 유닛이 과거 네트워크의 모든 정보를 가지고 미래를 예측해야한다. 그래서, output 유닛은 명백하게 학습 데이터의 타겟에 대해 학습된다. 사용자는 과거 모든 입력의 기록을 모아둘 필요가 없어진다.&lt;/p&gt;

&lt;p&gt;hidden-to-hidden 연결을 제거함으로 얻는 이득은, 시점 $t$에서 예측하는 데 필요한 loss의 계산이 모든 시점 $t$에 대한 관계성이 없어진다. 따라서 학습 단계는 병렬처리 가능하며, 각 시점 $t$에서의 gradient 계산은 독립적으로 수행 가능하다.&lt;/p&gt;

&lt;p&gt;output에서 바로 모델이 학습 하는 경우를 teacher forcing 이라고 한다. 이는 maximum likelihood criterion을 따르며, ground truth $\hat(y)^{(t)}$가 $t+1$ 시점의 입력으로 사용된다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;두 시점의 sequence를 예를 들어보면, conditional maximum likelihood criterion은 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \log{p} (y^{(1)}, y^{(2)} | x^{(1)}, x^{(2)})$&lt;/p&gt;

&lt;p&gt;$ = \log{p} (y^{(2)} | y^{(1)}, x^{(1)}, x^{(2)})  +  \log{p} (y^{(1)} | x^{(1)}, x^{(2)}) $&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unfolding Computational Graphs</title>
      <link>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</link>
      <pubDate>Thu, 02 Jun 2016 00:59:05 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-1-unfolding-computational-graphs&#34;&gt;10.1 Unfolding Computational Graphs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Classical Dynamic System&lt;/strong&gt;:
$ S^{ (t) }=f(s^{ (t-1) };\theta ) $, 여기서 $s^{(t)}$ 는 시스템의 상태를 나타낸다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dynamical system driven by an external signal&lt;/strong&gt; $ x^{(t)} $:
$ S^{ (t) }=f(s^{ (t-1) }, x^{(t)} ;\theta ) $&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) 은 다양한 방법으로 만들수 있다. 대부분은 feedforward neural network로 간주되며, recurrence (재귀표현)를 포함하고 있다면 Recurrent Neural Networks (RNN) 이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;앞서 나온 &lt;strong&gt;Dynamical System&lt;/strong&gt; 식을 이용해, 다음과 같이 유사한 형태의 식으로 RNN의 hidden unit을 정의한다.
$$ h^{(t)} = f(h^{ (t-1) }, x^{(t)} ;\theta ) $$&lt;/p&gt;

&lt;p&gt;예를 들어, RNN이 과거 데이터를 학습하고, 미래를 예측하는 일을 수행한다고 하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;입력: $ x^{(t)}$ (시점 $t$ 까지의 입력)&lt;/li&gt;
&lt;li&gt;종합: $ h^{(t)}$ (정보 손실이 있는 종합된 내용)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 과정을 통해 과거 정보에서 선택적으로 필요한 정보만 유지하여 종합한다. 예를 들어, RNN이 통계적 언어 모델링을 통해, 과거의 단어들을 바탕으로 다음에 나올 단어를 예측한다. 이를 위해, 시점 (time step) $t$ 까지 모든 입력을 다 기억할 필요는 없다. 일정한 정보만으로도 문장의 나머지 단어들을 예측하기에 충분하다.&lt;/p&gt;

&lt;p&gt;RNN을 그림으로 묘사하는 두가지 방법이 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph&lt;/code&gt;: 모든 기능을 하나의 노드로만 표현.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;: 각 기능들이 각각의 노드로 표현. Unfolded 표현은 sequence 길이와 연관된 크기를 가진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unfolding 과정은 다음과 같은 장점을 지닌다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sequence 길이와 상관없이, 학습된 모델은 항상 같은 입력 크기를 가진다.&lt;/li&gt;
&lt;li&gt;같은 파라미터를 사용하는 전이 함수 (transition function) $f$ 를 사용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두가지 요인 때문에, 각 시점마다 $g^{(t)}$ 를 개별적으로 학습시키지 않아도 된다. 같은 파리미터가 공유되기 때문에, 단일 모델 $f$ 가 모든 sequence 길이와 모든 시점에서 동작한다.&lt;/p&gt;

&lt;p&gt;단일화, 공유되는 모델 학습은 일반화를 가능하게 한다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;학습 데이터상의 sequence 길이에 무관하다.&lt;/li&gt;
&lt;li&gt;적은 학습 데이터로도 예측이 가능하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두가지 RNN 표현법은 다음과 같이 각자의 용도가 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph (recurrent graph)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;간단명료하다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;각 단계에서 계산 수행을 분명하게 기술한다.&lt;/li&gt;
&lt;li&gt;진행 방향에 따라 아이디어를 묘사하기 쉽다.&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Forward): output과 loss의 계산&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Backward): gradient 계산&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>