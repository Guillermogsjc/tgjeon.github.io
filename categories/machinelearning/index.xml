<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machinelearning on Taegyun Jeon</title>
    <link>https://tgjeon.github.io/categories/machinelearning/</link>
    <description>Recent content in Machinelearning on Taegyun Jeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Taegyun Jeon</copyright>
    <lastBuildDate>Wed, 29 Jun 2016 10:49:16 +0900</lastBuildDate>
    <atom:link href="https://tgjeon.github.io/categories/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Stochastic Gradient Methods</title>
      <link>https://tgjeon.github.io/post/stochastic_gradient_methods/</link>
      <pubDate>Wed, 29 Jun 2016 10:49:16 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/stochastic_gradient_methods/</guid>
      <description>

&lt;h1 id=&#34;stochastic-gradient-methods-for-large-scale-machine-learning-part-1:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;Stochastic Gradient Methods for Large-Scale Machine Learning (Part 1)&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Original presentation materials: &lt;a href=&#34;http://www.icml.cc/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/tutorials/part-2.pdf&#34;&gt;Part2&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/tutorials/part-3.pdf&#34;&gt;Part3&lt;/a&gt; is written by Leon Bottou (Facebook AI Research), Frank E. Curtis (Lehigh University), and Jorge Nocedal (Northwestern University).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 ICML 2016 Tutorial 중 &amp;ldquo;Stochastic Gradient Methods for Large-Scale Machine Learning&amp;rdquo; 의 내용을 한글로 정리한 포스트입니다. 해당 발표자료는 위 링크를 참고하여 확인하시기 바랍니다. 원 튜토리얼 자료와 같이 보시는 것을 권합니다.&lt;/p&gt;

&lt;p&gt;해당 튜토리얼은 &lt;a href=&#34;http://arxiv.org/abs/1606.04838&#34;&gt;&amp;ldquo;Optimization Methods for Large-Scale Machine Learning&amp;rdquo;&lt;/a&gt;, L. Bottou, F.E. Curtis, J. Nocedal, Prepared for SIAM Review 논문을 요약한 내용이라고 합니다. 다 자세한 내용을 보고싶으신 분은 위 논문을 참고하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;튜토리얼의-목표:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;튜토리얼의 목표&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Stochastic gradient (SG) 방법에 대해 알아본다.&lt;/li&gt;
&lt;li&gt;SG는 왜 중요해질까?&lt;/li&gt;
&lt;li&gt;핵심 매커니즘은 무엇인가?&lt;/li&gt;
&lt;li&gt;convex와 non-convex의 경우에 어떻게 행동한다고 할수 있는가?&lt;/li&gt;
&lt;li&gt;SG를 향상 시키기위해서 어떤 노력들이 있었는가?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;튜토리얼의-구성:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;튜토리얼의 구성&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Motivation for the stochastic gradient (SG) method&lt;/li&gt;
&lt;li&gt;Analysis of SG&lt;/li&gt;
&lt;li&gt;Beyond SG&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;문제-정의-problem-statement:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;문제 정의 (Problem statement)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;학습 데이터가 주어집니다. training set: $ {(x_1, y_1), &amp;hellip;, (x_n, y_n)} $&lt;/li&gt;
&lt;li&gt;손실 함수가 주어집니다. loss function: $ \ell(h,y) $

&lt;ul&gt;
&lt;li&gt;여기서 우리의 예측이 실제 학습 데이터의 label인 $y$와 얼마나 다른지 측정합니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;예측 함수는 $h(x;w)$ 입니다.

&lt;ul&gt;
&lt;li&gt;$x$는 입력 데이터 (input data), $w$는 학습 모델의 가중치 (weights of model) 입니다. 모델 $w$가 입력 $x$을 받아 예측 결과 $\hat {y}$를 출력으로 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 우리의 목표는 가장 최선의 예측을 하는 것입니다. 주어진 학습 데이터에 대해 예측 손실을 최소화하는 모델을 만들어서 이 목표를 달성하고자 합니다. 하나의 수식으로 표현하면 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{w}{\frac {1}{n} \sum _{i=1}^{n}{\ell(h(x_i; w), y_i)} } $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 학습 데이터에 대해 예측을 하고, 각 학습 데이터에 대한 예측이 학습 데이터의 label인 $y$와 차이가 적게 나타도록 하는 $w$가 우리의 학습 모델이 됩니다. 충분한 학습 데이터는 경험이라고 표현 할 수 있습니다. 우리의 학습 모델이 얼마나 큰 위험 요소 (Risk)를 가지고 있는지 표현해봅시다. 여기서 $f$는 손실 함수 (loss function) 입니다. 경험적 위험요소 (empirical risk)는 아래와 같이 표현됩니다. 각 학습 데이터 마다 loss를 계산해서 평균내어 risk로 나타냅니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터가 충분히 모였다면 데이터에 대한 확률 분포가 존재합니다. 이 때, 우리의 학습 데이터를 랜덤 변수 $\xi=(x_i, y_i)$ 로 표현합니다. 그렇다면 위험요소 (risk)는 기대값으로 나타낼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;expected risk: $R(w) = E[f(w;x_i)] $&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;stochastic-gradient-method-vs-batch-gradient-method:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;Stochastic Gradient Method vs Batch Gradient Method&lt;/h3&gt;

&lt;p&gt;이전에 표현했던 empirical risk minimization을 살펴봅시다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터를 하나씩 관찰하면서, 모델의 가중치는 아래와 같은 수식을 통해 변화됩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;weight update: $w_{k+1} = w_k - \alpha_k \nabla f_i(w_k),$ where $i \in$ {$1,&amp;hellip;,n$} choose at random

&lt;ul&gt;
&lt;li&gt;단순 반복을 통해 가능합니다. 데이터 1개씩만 보고 변화율 (gradient)을 변경합니다.&lt;/li&gt;
&lt;li&gt;i번째 데이터를 고르는 순서에 따라 확률 과정 (stochastic process)이 결정됩니다.&lt;/li&gt;
&lt;li&gt;gradient descent method가 아닙니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reference:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://projecteuclid.org/euclid.aoms/1177729586&#34;&gt;[Robibins-Monro&amp;rsquo;51]&lt;/a&gt;: H. Robbins and S. Monro. A Stochastic Approximation Method. Ann. Math. Statist. 22 (1951), no. 3, 400&amp;ndash;407.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면, batch gradient method로 넘어가봅시다. 일정 묶음의 수만큼 데이터를 확인하고, loss를 계산하여 risk를 모델 가중치 변화에 적용 시킵니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;batch gradient method: $w_{k+1} = w_k - \alpha_k \nabla R_n(w_k)$&lt;/li&gt;
&lt;li&gt;$w_{k+1} = w_k - \frac {\alpha_k}{n} \sum _{i=1}^{n}{\nabla f_i(w_k)}$

&lt;ul&gt;
&lt;li&gt;계산량이 늘어나게 됩니다.&lt;/li&gt;
&lt;li&gt;다양한 최적화 알고리즘을 선택하여 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;각 배치 별로 병렬처리가 가능해집니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 왜 stochastic gradient (SG) 기법이 더 탁월하다고 볼 수 있을까요? &lt;strong&gt;여기서 Risk ($R$)를 최적하 하기 위한 stochastic 기법과 batch 기법의 계산량의 상호보완적인 내용을 짚고 넘어가야 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;sg-bg:d651e37548ed21cc65094b1e7112d7f5&#34;&gt;SG &amp;gt; BG&lt;/h3&gt;

&lt;p&gt;stochastic gradient (SG) 기법은 batch 기법보다 더 효율적입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;생각해 볼 문제 #1

&lt;ul&gt;
&lt;li&gt;만약 집합 S의 10개의 복사본으로 데이터가 구성된다면,&lt;/li&gt;
&lt;li&gt;batch 기법으로 수행한다면 SG 기법의 경우보다 10배의 계산량이 요구됩니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;생각해 볼 문제 #2

&lt;ul&gt;
&lt;li&gt;데이터를 구성할 때, training set (40%), test set (30%), validation set (30%) 식으로 보통 구성합니다.&lt;/li&gt;
&lt;li&gt;20%, 10%, 혹은 1% 이런식의 구성은 의미가 없을까요?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://www.icml.cc/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, slide#9를 보면 LBFGS와 SGD의 실질적인 비교 결과를 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;LBFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;quasi-newton method와 유사한 최적화 기법입니다.&lt;/li&gt;
&lt;li&gt;제한된 메모리를 가진 컴퓨터에서 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 알고리즘을 근사화 (approximation)시킨 기법입니다.&lt;/li&gt;
&lt;li&gt;기계 학습에서 파라미터 추정 (parameter estimation)에서 많이 쓰입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Slide#9에서, 초기 과정에서 SGD가 LBFGS보다 월등히 빠르게 수렴하는 것을 확인 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Slide#10에서는 Quadratic One-Dimensional example을 소개하고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{x \in \Re}\sum _{i=1}^{m} {(a_i x - b_i)}^{2} $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 예제에서 처럼 혼동되는 구역 (region of confusion)에서 2차식을 임의로 찾아서 목표로 하는 리스크 감소가 가능 할까요?&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>