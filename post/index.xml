<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Taegyun Jeon</title>
    <link>https://tgjeon.github.io/post/</link>
    <description>Recent content in Posts on Taegyun Jeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Taegyun Jeon</copyright>
    <lastBuildDate>Tue, 23 Aug 2016 12:54:32 +0900</lastBuildDate>
    <atom:link href="https://tgjeon.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>RNNs in Tensorflow, A Practical Guide and Undocumented Features</title>
      <link>https://tgjeon.github.io/post/rnns-in-tensorflow/</link>
      <pubDate>Tue, 23 Aug 2016 12:54:32 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnns-in-tensorflow/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/&#34;&gt;Original post&lt;/a&gt; is written by Denny Britz (Google Brain team).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 위 내용을 한글로 정리한 내용입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이전 &lt;a href=&#34;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&#34;&gt;튜토리얼&lt;/a&gt;에서, Recurrent Neural Networks (RNNs)에 대한 이론들에 대해서 살펴보고, 간단한 RNN을 기초부터 만들어보는 과정을 진행했습니다. 이 과정들은 유용했지만, 실제로 RNNs에 대한 고수준의 기초요소들을 제공하는 Tensorflow와 같이 라이브러리를 사용해봅시다.&lt;/p&gt;

&lt;p&gt;RNNs을 함수 호출해서 사용하는 것처럼 쉽게 쓰면 좋겠지만, 현실은 만만치 않습니다. 이번 포스트에서는 Tensorflow를 이용하여 RNNs을 실질적으로 동작시켜보고, 특히 공식 사이트에서 문서화 되지 않은 기능들에 대해 다뤄보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;본 포스트는 Jupyer 노트북이 포함된 Github 저장소에 아래와 같은 예제들을 다루고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 사용하기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching과 Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/bidirectional_rnn.ipynb&#34;&gt;Bidirectional Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/rnn_cell_wrappers.py.ipynb&#34;&gt;RNN Cells과 Cell Wrappers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/loss_masking.py.ipynb&#34;&gt;Masking the Loss&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;데이터-전처리-tf-sequenceexample-사용하기&#34;&gt;데이터 전처리: tf.SequenceExample 사용하기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RNNs은 순차적인 데이터를 사용하며, 이 순차적인 데이터는 입력과 출력을 여러 시간 스텝으로 구성되어 있습니다. Tensorflow는 순차적 데이터: &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto&#34;&gt;tf.SequenceExample&lt;/a&gt; 를 다루기 위해 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;프로토콜 버퍼&lt;/a&gt;가 정의되어 있습니다.&lt;/p&gt;

&lt;p&gt;사용자는 Python/Numpy 배열로부터 직접 데이터를 불러올 수 있습니다. 하지만, &lt;code&gt;tf.SequenceExample&lt;/code&gt;가 더 관심 대상이므로 이것을 사용해보도록 합시다. 이 자료 구조는 비순차적 특징 (non-sequential features)은 &lt;code&gt;&amp;quot;context&amp;quot;&lt;/code&gt;로, 순차적 특징 (sequential features)은 &lt;code&gt;&amp;quot;feature_lists&amp;quot;&lt;/code&gt;로 구성됩니다. 장황하긴 하지만, 이것이 주는 장점은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;쉬운 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#distributed-tensorflow&#34;&gt;분산 학습&lt;/a&gt;&lt;/strong&gt;: 데이터를 여러개의 SequenceExamples을 포함하는 &lt;code&gt;TFRecord&lt;/code&gt; 파일들로 나누고, Tensorflow에 탑재된 분산 학습 기능을 이용합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;재사용성 (Reusability)&lt;/strong&gt;: 다른 사용자들도 본인이 만든 모델을 가져다가 자신들의 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 형태로 바꿔서 사용할 수 있습니다. 모델 코드 부분을 수정할 필요가 없습니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tensorflow의 데이터 불러오기 파이프라인 함수 사용&lt;/strong&gt;: &lt;code&gt;tf.parse_single_sequence_example&lt;/code&gt;과 같이 사용 가능합니다. &lt;code&gt;tf.learn&lt;/code&gt;과 같은 라이브러리 역시 데이터 입력을 프로토콜 버퍼 포맷으로 입력될 것을 예상하여, 간편한 함수를 지원합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;데이터 전처리와 모델 코드의 분리&lt;/strong&gt;: &lt;code&gt;tf.SequenceExample&lt;/code&gt;을 이용하게 되면, 사용자로 하여금 데이터 전처리와 Tensorflow 모델 코드 부분을 분리하도록 합니다. 이것은 소스코드 작성에 매우 유익한 부분이며, 입력 데이터가 어떤 형태로 들어올지 가정하지 않아도 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;실제로, 사용자가 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 포맷으로 변환하는 작은 스크립트를 작성하고, 그다음 하나 혹은 여러개의 &lt;code&gt;TFRecord&lt;/code&gt; 파일을 작성합니다. 이 &lt;code&gt;TFRecord&lt;/code&gt;파일은 Tensorflow가 파싱 (parsing)하게 되고, 사용자 모델의 입력이 됩니다:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;사용자의 데이터를 &lt;code&gt;tf.SequenceExample&lt;/code&gt; 포맷으로 변환합니다.&lt;/li&gt;
&lt;li&gt;serialized 데이터를 &lt;code&gt;TFRecord&lt;/code&gt;로 하나 혹은 여러개 파일로 작성합니다.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#TFRecordReader&#34;&gt;&lt;code&gt;tf.TFRecordReader&lt;/code&gt;&lt;/a&gt;를 이용하여 examples을 파일로부터 읽어옵니다.&lt;/li&gt;
&lt;li&gt;각 example을 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/python/ops/parsing_ops.py&#34;&gt;&lt;code&gt;tf.parse_single_sequence_example&lt;/code&gt;&lt;/a&gt;를 이용해 파싱합니다. (아직 공식 문서화되지 않은 기능입니다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sequences = [[1, 2, 3], [4, 5, 1], [1, 2]]
label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]
 
def make_example(sequence, labels):
    # 결과값은 example입니다.
    ex = tf.train.SequenceExample()
    # non-sequential feature 부분입니다. (데이터를 설명하는 정보)
    sequence_length = len(sequence)
    ex.context.feature[&amp;quot;length&amp;quot;].int64_list.value.append(sequence_length)
    # sequential features 부분인 feature_lists 부분입니다. (실제 데이터)
    fl_tokens = ex.feature_lists.feature_list[&amp;quot;tokens&amp;quot;]
    fl_labels = ex.feature_lists.feature_list[&amp;quot;labels&amp;quot;]
    for token, label in zip(sequence, labels):
        fl_tokens.feature.add().int64_list.value.append(token)
        fl_labels.feature.add().int64_list.value.append(label)
    return ex
 
# 모든 examples을 하나의 TFRecord파일로 작성합니다.
with tempfile.NamedTemporaryFile() as fp:
    writer = tf.python_io.TFRecordWriter(fp.name)
    for sequence, label_sequence in zip(sequences, label_sequences):
        ex = make_example(sequence, label_sequence)
        writer.write(ex.SerializeToString())
    writer.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고, example을 파싱하여 사용합니다:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# 하나의 serialized example입니다.
# (TFRecordReader를 이용하여 하나의 example을 읽어올 수 있습니다.)
ex = make_example([1, 2, 3], [0, 1, 0]).SerializeToString()
 
# example을 파싱하는 방식을 정의합니다. (이름과 데이터 타입)
context_features = {
    &amp;quot;length&amp;quot;: tf.FixedLenFeature([], dtype=tf.int64)
}
sequence_features = {
    &amp;quot;tokens&amp;quot;: tf.FixedLenSequenceFeature([], dtype=tf.int64),
    &amp;quot;labels&amp;quot;: tf.FixedLenSequenceFeature([], dtype=tf.int64)
}
 
# example로 부터 파싱합니다.
context_parsed, sequence_parsed = tf.parse_single_sequence_example(
    serialized=ex,
    context_features=context_features,
    sequence_features=sequence_features
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;batching과-데이터-padding&#34;&gt;Batching과 데이터 Padding&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching and Padding 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow의 RNN 함수는 $[B, T, &amp;hellip;]$ 형태의 tensor를 입력으로 기대합니다. 여기서 $B$는 배치 사이즈, $T$는 각 입력의 시간 길이를 의미합니다. (예. 한 문장의 단어 수). 그리고 마지막 dimension은 사용자의 데이터와 관련있습니다. 문제를 눈치채셨나요? 보편적으로, 하나의 배치에 포함된 모든 sequence들이 길이 $T$와 같지 않다는 것입니다. 하지만 RNN 모델에 입력으로 집어넣어주기 위해서는 길이를 맞춰줘야 합니다. 보통은 padding을 통해 해결합니다: 각 example에 0을 채워 넣어서 sequence의 길이를 같게 맞춰줍니다.&lt;/p&gt;

&lt;p&gt;만약, 사용자의 sequence중 하나의 길이가 1000이라고 합시다. 하지만 sequences의 평균 길이가 20이라고 한다면 어떨까요? 만약 모든 example에 대해 길이 1000개에 맞춰서 padding을 하게 되면, 엄청난 공간 (뿐만 아니라 계산 시간)의 낭비가 발생합니다. 바로 여기서 batch padding이 필요합니다. 만약 사용자가 32개의 배치들을 만들었다면, 단지 각 배치에 있는 examples을 같은 크기 (해당 배치의 최대 길이의 example 크기에 맞춰서)로만 padding 시키면 되는 것입니다. 이 방식대로라면, 정말 긴 example은 오직 하나의 배치에만 영향을 미칩니다. 다른 모든 배치의 example 데이터들은 영향에서 벗어날 수 있습니다.&lt;/p&gt;

&lt;p&gt;실제로 다루기엔 지저분해보이지만, 다행스럽게도 Tensorflow에는 batch padding 기능을 포함하고 있습니다. 만약 사용자가 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#batch&#34;&gt;&lt;code&gt;tf.train.batch&lt;/code&gt;&lt;/a&gt;를 호출할 때 &lt;code&gt;dynamic_pad=True&lt;/code&gt;로 설정한다면, 반환되는 batch 결과값들은 자동적으로 0이 padding됩니다. 편리하네요! lower-level 옵션은 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops.html#PaddingFIFOQueue&#34;&gt;&lt;code&gt;tf.PaddingFIFOQueue&lt;/code&gt;&lt;/a&gt;를 사용하는 것입니다.&lt;/p&gt;

&lt;h4 id=&#34;side-note-단어-vocabulary-종류-class-를-사용할때는-0으로-padding-하는-것을-주의해서-쓰세요&#34;&gt;Side note: 단어(Vocabulary)/종류(class)를 사용할때는 0으로 padding 하는 것을 주의해서 쓰세요!&lt;/h4&gt;

&lt;p&gt;만약 사용자가 분류 (classification) 문제를 다루고 있고, 입력 tensor가 class IDs (0, 1, 2, &amp;hellip;)를 포함한다면, padding을 사용할때 주의해야 합니다. tensor를 0으로 padding 한다면, 0-padding과 &amp;ldquo;class 0&amp;rdquo;과의 차이점을 구분할 수 없는 경우가 생깁니다. 사용자 모델이 다루고자 하는 문제에 따라 달라지겠지만, 이 이슈에 대해서 안전하고 싶다면 &amp;ldquo;class 0&amp;rdquo; 대신 &amp;ldquo;class 1&amp;rdquo;로 부터 시작하도록 사용해보세요. (이 예제가 masking the loss function 부분에서 문제를 발생시킵니다. 자세한 내용은 아래에서 설명하도록 하겠습니다.)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# [0, 1, 2, 3, 4 ,...]
x = tf.range(1, 10, name=&amp;quot;x&amp;quot;)
 
# A queue that outputs 0,1,2,3,...
range_q = tf.train.range_input_producer(limit=5, shuffle=False)
slice_end = range_q.dequeue()
 
# Slice x to variable length, i.e. [0], [0, 1], [0, 1, 2], ....
y = tf.slice(x, [0], [slice_end], name=&amp;quot;y&amp;quot;)
 
# Batch the variable length tensor with dynamic padding
batched_data = tf.train.batch(
    tensors=[y],
    batch_size=5,
    dynamic_pad=True,
    name=&amp;quot;y_batch&amp;quot;
)
 
# Run the graph
# tf.contrib.learn takes care of starting the queues for us
res = tf.contrib.learn.run_n({&amp;quot;y&amp;quot;: batched_data}, n=1, feed_dict=None)
 
# Print the result
print(&amp;quot;Batch shape: {}&amp;quot;.format(res[0][&amp;quot;y&amp;quot;].shape))
print(res[0][&amp;quot;y&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다음과 같은 결과를 나타냅니다:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Batch shape: (5, 4)
[[0 0 0 0]
 [1 0 0 0]
 [1 2 0 0]
 [1 2 3 0]
 [1 2 3 4]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고 &lt;code&gt;PaddingFIFOQueue&lt;/code&gt;를 사용한 결과도 동일합니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ... Same as above
 
# Creating a new queue
padding_q = tf.PaddingFIFOQueue(
    capacity=10,
    dtypes=tf.int32,
    shapes=[[None]])
 
# Enqueue the examples
enqueue_op = padding_q.enqueue([y])
 
# Add the queue runner to the graph
qr = tf.train.QueueRunner(padding_q, [enqueue_op])
tf.train.add_queue_runner(qr)
 
# Dequeue padded data
batched_data = padding_q.dequeue_many(5)
 
# ... Same as above
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnn과-dynamic-rnn&#34;&gt;RNN과 Dynamic_RNN&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;DYNAMIC_RNN 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow는 두가지 종류의 RNNs을 제공하고 있습니다: &lt;code&gt;tf.nn.rnn&lt;/code&gt;과 &lt;code&gt;tf.nn.dynamic_rnn&lt;/code&gt;. 무엇을 사용할까요?&lt;/p&gt;

&lt;p&gt;내부적으로, &lt;code&gt;tf.nn.rnn&lt;/code&gt;은 고정된 길이를 가지는 RNN을 펼친 그래프를 생성합니다. 만약 200개의 시간 스텝을 입력으로 하여 &lt;code&gt;tf.nn.rnn&lt;/code&gt;을 사용한다면, 200개의 RNN 스텝을 가지는 고정된 (static) 그래프가 만들어 집니다. 첫째, 그래프의 생성은 느립니다. 둘째, 원래 정의했던 길이보다 더 긴 길이 (200개 이상)의 sequence를 처리하지 못합니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tf.nn.dynamic_rnn&lt;/code&gt;은 이 문제들을 해결할 수 있습니다. &lt;code&gt;tf.while&lt;/code&gt; loop를 이용하여, 실행될때 동적으로 그래프를 생성합니다. 이를 통해 빠르게 그래프를 생성하고, 다양한 길이의 배치들을 입력으로 처리 할 수 있습니다. 성능은 어떨까요? 일반적으로 생각하기에 static RNN이 그래프를 미리 생성해두기 때문에, dynamic RNN보다 빠를것이라고 생각합니다. 하지만, 제 경험상 그렇지 않았습니다.&lt;/p&gt;

&lt;p&gt;간단히 얘기하면, 그냥 &lt;strong&gt;&lt;code&gt;tf.nn.dynamic_rnn&lt;/code&gt;&lt;/strong&gt;을 쓰세요. &lt;code&gt;tf.nn.rnn&lt;/code&gt;을 사용해서 얻을수 있는 장점이 없습니다. &lt;code&gt;tf.nn.rnn&lt;/code&gt;이 앞으로 사라져도 놀랍지 않습니다.&lt;/p&gt;

&lt;h3 id=&#34;sequence-길이를-rnn에-전달하기&#34;&gt;Sequence 길이를 RNN에 전달하기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/bidirectional_rnn.ipynb&#34;&gt;Bidirectional RNN 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Padding 된 입력을 Tensorflow의 RNN 함수들을 이용할 때, &lt;code&gt;sequence_length&lt;/code&gt; 파라미터를 전달해 주는 것이 중요합니다. 개인적인 생각으로 이 파라미터는 선택적으로 쓰기보단, 필수적으로 꼭 사용하는게 좋습니다. &lt;code&gt;sequence_length&lt;/code&gt;는 두가지 효과가 있습니다. 1. 계산시간을 절약해줍니다. 2. 정확함을 보장해줍니다.&lt;/p&gt;

&lt;p&gt;2개의 example을 가진 배치가 있다고 합시다. example 의 길이는 13이고, 다른 example의 길이는 20입니다. 길이가 13인 example은 0으로 채워져서 (0-padded) 길이가 20이 됩니다. 각각은 128개의 숫자로 된 벡터입니다. 그렇다면 RNN tensor의 모양은 &lt;strong&gt;[2, 20, 128]&lt;/strong&gt;입니다. dynamic_rnn 함수는 (outputs, state) 형태의 튜플을 반환합니다. 여기서 &lt;strong&gt;output&lt;/strong&gt;은 &lt;strong&gt;[2, 20, &amp;hellip;]&lt;/strong&gt; 형태의 tensor 이며, 마지막 차원은 각 시간 스텝의 RNN 결과입니다. &lt;strong&gt;state&lt;/strong&gt;는 각 example에 대한 최종 상태이며, tensor 크기는 &lt;strong&gt;[2, &amp;hellip;]&lt;/strong&gt;입니다. 마지막 차원의 값은 사용하는 RNN cell에 따라 달라집니다.&lt;/p&gt;

&lt;p&gt;여기서 문제가 발생합니다. 시간 스텝 13에 도달 했을 때, 배치의 첫번째 example (총 길이 (20) = 본래 길이 (13) + 0채우기 (7))은 이미 &amp;ldquo;완료&amp;rdquo;된 상태고, 사용자는 더 이상 추가적인 계산이 이루어지길 원하지 않습니다. 두번째 example은 상황이 다르므로 (총 길이 (20) = 본래 길이 (20)), 시간 스텝 20까지 RNN이 계산해야합니다. &lt;strong&gt;sequence_length=[13, 20]&lt;/strong&gt;을 전달한다면, 사용자는 Tensorflow에게 첫번째 example은 시간 스텝 13까지만 계산하고, 시간 스텝 13 이후부터는, 각 상태를 복사해서 끝까지 전달만 합니다. 시간 스텝 13 이후의 모든 출력은 0으로 설정 될 것입니다. 이 과정을 통해서 계산 시간을 절약할 수 있습니다. 하지만, 더 중요한 것은 만약 &lt;strong&gt;sequence_length&lt;/strong&gt;를 전달하지 않았을 경우, 잘못된 결과를 얻을 수 있습니다. &lt;strong&gt;sequence_length&lt;/strong&gt;를 전달하지 않는다면, Tensorflow는 T=13부터 상태를 복사해서 전달하는 것이 아니라, T=20까지 계속 상태를 계산해 나갑니다. 이것은 T=13이후 부터 의도하지 않은 입력인 padding 된 값들을 통해 상태를 계산한다는 뜻입니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Create input data
X = np.random.randn(2, 10, 8)
 
# The second example is of length 6 
X[1,6:] = 0
X_lengths = [10, 6]
 
cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)
 
outputs, last_states = tf.nn.dynamic_rnn(
    cell=cell,
    dtype=tf.float64,
    sequence_length=X_lengths,
    inputs=X)
 
result = tf.contrib.learn.run_n(
    {&amp;quot;outputs&amp;quot;: outputs, &amp;quot;last_states&amp;quot;: last_states},
    n=1,
    feed_dict=None)
 
assert result[0][&amp;quot;outputs&amp;quot;].shape == (2, 10, 64)
 
# Outputs for the second example past past length 6 should be 0
assert (result[0][&amp;quot;outputs&amp;quot;][1,7,:] == np.zeros(cell.output_size)).all()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;bidirectional-rnn&#34;&gt;Bidirectional RNN&lt;/h3&gt;

&lt;p&gt;기본 RNN을 사용하여 예측하고자 할때, 우리는 &amp;ldquo;과거&amp;rdquo;만 고려합니다. 특정한 일에는 맞는 말입니다 (예. 다음 나타날 단어 예상). 하지만 특정 일에 대해서는 과거와 미래 모두를 고려하는 것이 도움이 될 때도 있습니다. 태그를 붙이는 일을 생각해봅시다. 품사 태깅이 대표적이겠죠. 문장의 각 단어들을 품사를 할당하는 일입니다. 우리는 이미 하나의 문장에 나타나는 단어들 모두를 알고 있다고 합시다. 그렇다면 우리는 각 단어에 대해서 왼쪽 단어 (과거) 뿐 아니라, 오른쪽 단어 (미래)도 같이 해당 단어의 품사를 예측하는데 사용하고 싶습니다. Bidirectional RNN이 정확하게 이 목적에 부합합니다. Bidirectional RNN은 두개의 RNN을 결합한 형태입니다. 하나는 &amp;ldquo;왼쪽에서 오른쪽으로&amp;rdquo; 진행하는 것과 &amp;ldquo;오른쪽에서 왼쪽으로&amp;rdquo; 역행하는 것이죠. 이것은 태깅하는데 많이 사용되며, 하나의 시퀀스를 고정 길이 벡터로 끼워넣기 위해 사용됩니다. (이 포스트의 범위를 벗어난 내용입니다.)&lt;/p&gt;

&lt;p&gt;기본 RNN처럼, Tensorflow에서는 고정적 (static), 동적 (dynamic)인 버전의 Bidirectional RNN을 제공하고 있습니다. 이 포스트가 작성된 시점 (August 21, 2016)에는 &lt;strong&gt;&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py&#34;&gt;bidirectional_dynamic_rnn&lt;/a&gt;&lt;/strong&gt;가 아직 문서화되진 않았지만, 고정적 (static) &lt;code&gt;bidrectional_rnn&lt;/code&gt;을 쓰는 것보단 더 좋습니다.&lt;/p&gt;

&lt;p&gt;Bidirectional RNN의 가장 큰 차이점은 정방향 (forward)과 역방향 (backward)에 대해 각기 분리된 다른 cell을 인자로 취합니다. 그리고 반환값인 outputs과 states도 마찬가지로, 정방향과 역방향에 대한 반환값을 각각 가지게 됩니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X = np.random.randn(2, 10, 8)
 
X[1,6,:] = 0
X_lengths = [10, 6]
 
cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)
 
outputs, states  = tf.nn.bidirectional_dynamic_rnn(
    cell_fw=cell,
    cell_bw=cell,
     dtype=tf.float64,
    sequence_length=X_lengths,
    inputs=X)
 
output_fw, output_bw = outputs
states_fw, states_bw = states
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;rnn-cells-wrappers-multi-layer-rnns&#34;&gt;RNN Cells, Wrappers, Multi-layer RNNs&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/rnn_cell_wrappers.py.ipynb&#34;&gt;RNN Cell 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;모든 Tensorflow의 RNN 함수들은 &lt;strong&gt;Cell&lt;/strong&gt;을 인자로 받습니다. LSTMs과 GRUs가 가장 많이 사용되는 cells입니다. 물론 다른 종류도 있지만, 모두 문서화되진 않았습니다. 현재 어떤 cell들이 사용가능한지 확인할 수 있는 최선의 방법은 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py&#34;&gt;rnn_cell.py&lt;/a&gt;와 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py&#34;&gt;contrib/rnn_cell&lt;/a&gt;을 살펴보는 것입니다.&lt;/p&gt;

&lt;p&gt;이 포스트가 작성된 시점에서, 기본적인 RNN cell과 wrapper는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;BasicRNNCell&lt;/strong&gt;: 기본적인 RNN cell.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRUCell&lt;/strong&gt;: &lt;a href=&#34;http://arxiv.org/abs/1406.1078&#34;&gt;Gated Recurrent Unit&lt;/a&gt; cell.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BasicLSTMCell&lt;/strong&gt;: &lt;a href=&#34;http://arxiv.org/abs/1409.2329&#34;&gt;Recurrent Neural Network Regularization&lt;/a&gt; 논문 기반 LSTM cell입니다. peephole 연결과 cell clipping 기능이 없습니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSTMCell&lt;/strong&gt;: 더 복잡한 LSTM cell입니다. peephole연결과 cell clipping기능이 옵션으로 선택 가능합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MultiRNNCell&lt;/strong&gt;: 여러개의 RNN cell을 연결하여, Multi-layer cell로 구성해주는 wrapper입니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DropoutWrapper&lt;/strong&gt;: RNN cell의 입력과 출력 연결에 대해 dropout 기능을 추가해주는 wrapper입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Contributed RNN cell과 wrapper는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CoupledInputForgetGateLSTMCell&lt;/strong&gt;: 확장된 &lt;strong&gt;LSTMCell&lt;/strong&gt;인 CoupledInputForgetGate (CIFG) cell입니다. &lt;a href=&#34;http://arxiv.org/abs/1503.04069&#34;&gt;LSTM: A Search Space Odyssey&lt;/a&gt;를 기반으로 합니다.&lt;/li&gt;
&lt;li&gt;TimeFreqLSTMCell: Time-Frequency LSTM Cell 입니다. &lt;a href=&#34;http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45401.pdf&#34;&gt;Modeling Time-Frequency Patterns with LSTM vs. Convolutional Architectures for LVCSR Tasks&lt;/a&gt; 논문을 기반으로 합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GridLSTMCell&lt;/strong&gt;: &lt;a href=&#34;http://arxiv.org/abs/1507.01526&#34;&gt;Grid Long Short-Term Memory&lt;/a&gt; 논문을 기반으로 합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AttentionCellWrapper&lt;/strong&gt;: 기존 RNN cell에 Attention기능을 추가합니다. &lt;a href=&#34;https://arxiv.org/abs/1601.06733&#34;&gt;Long Short-Term Memory-Networks for Machine Reading&lt;/a&gt; 논문을 기반으로 합니다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSTMBlockCell&lt;/strong&gt;: 기본 LSTM cell의 빠른 버전입니다. (&lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/lstm_ops.py&#34;&gt;lstm_ops.py&lt;/a&gt;에 위치합니다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RNN cell과 wrapper는 아래와 같이 간단히 사용할 수 있습니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)
cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, output_keep_prob=0.5)
cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell] * 4, state_is_tuple=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;padded-example에-대해-sequence-loss-계산하기&#34;&gt;Padded example에 대해 Sequence loss 계산하기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/loss_masking.py.ipynb&#34;&gt;Loss 계산에 대한 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Sequence 예측에 대해서, 각 타임 스텝마다 예측하길 원할 때가 있습니다. 예를 들어, 언어 모델링에서 한 문장에서 나타나는 각 단어들에 대해 다음 나타날 단어를 예측하고자 합니다. 만약 모든 sequence가 동일한 길이라면, Tensorflow의 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py&#34;&gt;sequence_loss와 sequence_loss_by_example&lt;/a&gt;를 사용하여 cross-entropy loss를 계산할 수 있습니다.&lt;/p&gt;

&lt;p&gt;그러나, 현재 &lt;code&gt;sequence_loss&lt;/code&gt;는 dynamic_rnn으로 부터 얻어지는 가변 길이 sequence에 대해 지원하지 않습니다. padding을 통해 sequence길이를 맞춴뒤, 각 타임 스텝마다 그리고 padded 위치에서 loss를 계산한 다는 것은 무의미합니다. 해결책은 padded된 위치에 대해 마스킹 처리하는 가중치 행렬을 만드는겁니다.&lt;/p&gt;

&lt;p&gt;아래에서 0-class를 사용할 경우, 왜 0-padding이 문제가 되는지 볼 수 있습니다. 만약 마스크를 만들기 위해 &lt;strong&gt;tf.sign(tf.to_float(y))&lt;/strong&gt;을 사용할 때, &amp;ldquo;0-class&amp;rdquo;도 마스킹 처리되서 없어져버리는 경우가 발생합니다. 이를 방지하기 위해 sequence 길이 정보를 이용해 마스크를 만들수도 있지만, 훨씬 더 복잡해집니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Batch size
B = 4
# (Maximum) number of time steps in this batch
T = 8
RNN_DIM = 128
NUM_CLASSES = 10
 
# The *acutal* length of the examples
example_len = [1, 2, 3, 8]
 
# The classes of the examples at each step (between 1 and 9, 0 means padding)
y = np.random.randint(1, 10, [B, T])
for i, length in enumerate(example_len):
    y[i, length:] = 0  
     
# The RNN outputs
rnn_outputs = tf.convert_to_tensor(np.random.randn(B, T, RNN_DIM), dtype=tf.float32)
 
# Output layer weights
W = tf.get_variable(
    name=&amp;quot;W&amp;quot;,
    initializer=tf.random_normal_initializer(),
    shape=[RNN_DIM, NUM_CLASSES])
 
# Calculate logits and probs
# Reshape so we can calculate them all at once
rnn_outputs_flat = tf.reshape(rnn_outputs, [-1, RNN_DIM])
logits_flat = tf.batch_matmul(rnn_outputs_flat, W)
probs_flat = tf.nn.softmax(logits_flat)
 
# Calculate the losses 
y_flat =  tf.reshape(y, [-1])
losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits_flat, y_flat)
 
# Mask the losses
mask = tf.sign(tf.to_float(y_flat))
masked_losses = mask * losses
 
# Bring back to [B, T] shape
masked_losses = tf.reshape(masked_losses,  tf.shape(y))
 
# Calculate mean loss
mean_loss_by_example = tf.reduce_sum(masked_losses, reduction_indices=1) / example_len
mean_loss = tf.reduce_mean(mean_loss_by_example)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://tgjeon.github.io/post/rnn_rnn/</link>
      <pubDate>Tue, 05 Jul 2016 05:33:52 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_rnn/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-2-recurrent-neural-networks-rnns&#34;&gt;10.2 Recurrent Neural Networks (RNNs)&lt;/h3&gt;

&lt;p&gt;앞선 &lt;a href=&#34;https://tgjeon.github.io/post/rnn_unfolding_computational_graph/&#34;&gt;포스트&lt;/a&gt;에서 설명한 그래프 풀기 (graph unrolling)과 파라미터 공유 (parameter sharing)을 통해 다양한 형태의 recurrent neural networks를 디자인 할 수 있다.&lt;/p&gt;

&lt;p&gt;Recurrent Neural Networks의 중요한 디자인 패턴들은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;그림 10.3

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (h^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.4

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden-Output (hidden/output unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (o^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.5

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (최종 시점 $\tau$에만), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h^{\tau}, o^{\tau}), (o^\tau, L^\tau), (L^\tau, y^\tau)$ (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;처음 소개된 그림 10.3과 같은 형태는, recurrent neural networks의 가장 대표적인 형태이며, 이번 내용에서 가장 많이 설명될 것이다. 이와 같은 형태는 Turing machine과 같은 계산 과정을 통해 수행된다고 생각하면 된다. 시점 $t$의 갯수 (점근적 선형으로 증가하는) 만큼의 입력을 받아 해당 시점 이후의 출력을 가진다. 이는 근사치가 아닌 정확한 계산 결과이며 이산값으로 나타낸다.&lt;/p&gt;

&lt;p&gt;그림 10.3에서 동작하는 forward propagation 수식을 살펴보자. 개념적인 이야기를 다루고 있기 때문에, activation function, loss function, output 형태를 언급하지 않고 있다. 따라서, activation function은 $\tanh$로 두고 output은 discrete 값을 가정한다. 그리고 RNN 모델은 단어나 문자를 예측하는데 사용된다고 가정하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;output $o$는 각 이산값에 대해 정규화되지 않은 확률 분포로 나타낸다.&lt;/li&gt;
&lt;li&gt;최종 예측값은 $\hat{y}$는 출력 $o$에 대해 softmax()를 적용하여 정규화된 확률 값을 가진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forward propagation은 다음과 같이 동작한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Initial state: $h^{(0)}$로 부터 시작.&lt;/li&gt;
&lt;li&gt;Input-to-hidden ($U$)과 hidden-to-hidden ($W$): $a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$&lt;/li&gt;
&lt;li&gt;Activation: $h^{(t)} = \tanh(a^{(t)})$&lt;/li&gt;
&lt;li&gt;hidden-to-output ($V$): $o^{(t)} = c + Vh^{(t)}$&lt;/li&gt;
&lt;li&gt;Normailized discrete output: ${\hat{y}}^{(t)} = softmax(o^{(t)})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모델은 입력 sequence와 출력 sequence의 길이가 동일하다. 전체 입,출력 sequence에 대한 loss는 각 시점 (time steps)마다의 loss를 모두 더한 것과 같다.&lt;/p&gt;

&lt;p&gt;$ L(${ $x^{(1)}, &amp;hellip;, x^{(\tau)} $}, { $y{(1)}, &amp;hellip;, y^{(\tau)} $}$)$&lt;/p&gt;

&lt;p&gt;$= \sum _{t}{L^{(t)}} $&lt;/p&gt;

&lt;p&gt;$= -\sum _{t}{\log{p}} _{model} (y^{(t)} | ${ $x^{(1)}, &amp;hellip;, x^{(t)} $}$)$&lt;/p&gt;

&lt;p&gt;$L^{(t)} $가 입력 $x^{(1)}, &amp;hellip;, x^{(t)}$이 주어졌을 때, 출력 $y^{(t)}$에 대한 negative log-likelihood라고 하자.
gradient를 계산하는 과정은 각 시점 (time steps)에 대해 수행된다. 수행 시간은 $O(\tau)$이며, 병렬처리가 불가능하다.
이 모델은 강력하지만 학습 과정에서 많은 계산량을 요구한다. 이를 &lt;em&gt;back-propagation through time&lt;/em&gt; 혹은 &lt;em&gt;BPTT&lt;/em&gt; 라고 한다.&lt;/p&gt;

&lt;h3 id=&#34;10-2-1-teacher-forcing-and-networks-with-output-recurrence&#34;&gt;10.2.1 Teacher Forcing and Networks with Output Recurrence&lt;/h3&gt;

&lt;p&gt;그림 10.4에서 보여주고 있는 RNN모델은 hidden-to-hidden 연결성이 부족하기 때문에 강력하지 않다. hidden-to-hidden 연결이 없기 때문에, output 유닛이 과거 네트워크의 모든 정보를 가지고 미래를 예측해야한다. 그래서, output 유닛은 명백하게 학습 데이터의 타겟에 대해 학습된다. 사용자는 과거 모든 입력의 기록을 모아둘 필요가 없어진다.&lt;/p&gt;

&lt;p&gt;hidden-to-hidden 연결을 제거함으로 얻는 이득은, 시점 $t$에서 예측하는 데 필요한 loss의 계산이 모든 시점 $t$에 대한 관계성이 없어진다. 따라서 학습 단계는 병렬처리 가능하며, 각 시점 $t$에서의 gradient 계산은 독립적으로 수행 가능하다.&lt;/p&gt;

&lt;p&gt;output에서 바로 모델이 학습 하는 경우를 teacher forcing 이라고 한다. 이는 maximum likelihood criterion을 따르며, ground truth $\hat(y)^{(t)}$가 $t+1$ 시점의 입력으로 사용된다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;두 시점의 sequence를 예를 들어보면, conditional maximum likelihood criterion은 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \log{p} (y^{(1)}, y^{(2)} | x^{(1)}, x^{(2)})$&lt;/p&gt;

&lt;p&gt;$ = \log{p} (y^{(2)} | y^{(1)}, x^{(1)}, x^{(2)})  +  \log{p} (y^{(1)} | x^{(1)}, x^{(2)}) $&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Gradient Methods</title>
      <link>https://tgjeon.github.io/post/stochastic_gradient_methods/</link>
      <pubDate>Wed, 29 Jun 2016 10:49:16 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/stochastic_gradient_methods/</guid>
      <description>

&lt;h1 id=&#34;stochastic-gradient-methods-for-large-scale-machine-learning-part-1&#34;&gt;Stochastic Gradient Methods for Large-Scale Machine Learning (Part 1)&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Original presentation materials: &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-2.pdf&#34;&gt;Part2&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-3.pdf&#34;&gt;Part3&lt;/a&gt; is written by Leon Bottou (Facebook AI Research), Frank E. Curtis (Lehigh University), and Jorge Nocedal (Northwestern University).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 ICML 2016 Tutorial 중 &amp;ldquo;Stochastic Gradient Methods for Large-Scale Machine Learning&amp;rdquo; 의 내용을 한글로 정리한 포스트입니다. 해당 발표자료는 위 링크를 참고하여 확인하시기 바랍니다. 원 튜토리얼 자료와 같이 보시는 것을 권합니다.&lt;/p&gt;

&lt;p&gt;해당 튜토리얼은 &lt;a href=&#34;http://arxiv.org/abs/1606.04838&#34;&gt;&amp;ldquo;Optimization Methods for Large-Scale Machine Learning&amp;rdquo;&lt;/a&gt;, L. Bottou, F.E. Curtis, J. Nocedal, Prepared for SIAM Review 논문을 요약한 내용이라고 합니다. 다 자세한 내용을 보고싶으신 분은 위 논문을 참고하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;튜토리얼의-목표&#34;&gt;튜토리얼의 목표&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Stochastic gradient (SG) 방법에 대해 알아본다.&lt;/li&gt;
&lt;li&gt;SG는 왜 중요해질까?&lt;/li&gt;
&lt;li&gt;핵심 매커니즘은 무엇인가?&lt;/li&gt;
&lt;li&gt;convex와 non-convex의 경우에 어떻게 행동한다고 할수 있는가?&lt;/li&gt;
&lt;li&gt;SG를 향상 시키기위해서 어떤 노력들이 있었는가?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;튜토리얼의-구성&#34;&gt;튜토리얼의 구성&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Motivation for the stochastic gradient (SG) method&lt;/li&gt;
&lt;li&gt;Analysis of SG&lt;/li&gt;
&lt;li&gt;Beyond SG&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;문제-정의-problem-statement&#34;&gt;문제 정의 (Problem statement)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;학습 데이터가 주어집니다. training set: $ {(x_1, y_1), &amp;hellip;, (x_n, y_n)} $&lt;/li&gt;
&lt;li&gt;손실 함수가 주어집니다. loss function: $ \ell(h,y) $

&lt;ul&gt;
&lt;li&gt;여기서 우리의 예측이 실제 학습 데이터의 label인 $y$와 얼마나 다른지 측정합니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;예측 함수는 $h(x;w)$ 입니다.

&lt;ul&gt;
&lt;li&gt;$x$는 입력 데이터 (input data), $w$는 학습 모델의 가중치 (weights of model) 입니다. 모델 $w$가 입력 $x$을 받아 예측 결과 $\hat {y}$를 출력으로 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 우리의 목표는 가장 최선의 예측을 하는 것입니다. 주어진 학습 데이터에 대해 예측 손실을 최소화하는 모델을 만들어서 이 목표를 달성하고자 합니다. 하나의 수식으로 표현하면 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{w}{\frac {1}{n} \sum _{i=1}^{n}{\ell(h(x_i; w), y_i)} } $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 학습 데이터에 대해 예측을 하고, 각 학습 데이터에 대한 예측이 학습 데이터의 label인 $y$와 차이가 적게 나타도록 하는 $w$가 우리의 학습 모델이 됩니다. 충분한 학습 데이터는 경험이라고 표현 할 수 있습니다. 우리의 학습 모델이 얼마나 큰 위험 요소 (Risk)를 가지고 있는지 표현해봅시다. 여기서 $f$는 손실 함수 (loss function) 입니다. 경험적 위험요소 (empirical risk)는 아래와 같이 표현됩니다. 각 학습 데이터 마다 loss를 계산해서 평균내어 risk로 나타냅니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터가 충분히 모였다면 데이터에 대한 확률 분포가 존재합니다. 이 때, 우리의 학습 데이터를 랜덤 변수 $\xi=(x_i, y_i)$ 로 표현합니다. 그렇다면 위험요소 (risk)는 기대값으로 나타낼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;expected risk: $R(w) = E[f(w;x_i)] $&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;stochastic-gradient-method-vs-batch-gradient-method&#34;&gt;Stochastic Gradient Method vs Batch Gradient Method&lt;/h3&gt;

&lt;p&gt;이전에 표현했던 empirical risk minimization을 살펴봅시다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터를 하나씩 관찰하면서, 모델의 가중치는 아래와 같은 수식을 통해 변화됩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;weight update: $w_{k+1} = w_k - \alpha_k \nabla f_i(w_k),$ where $i \in$ {$1,&amp;hellip;,n$} choose at random

&lt;ul&gt;
&lt;li&gt;단순 반복을 통해 가능합니다. 데이터 1개씩만 보고 변화율 (gradient)을 변경합니다.&lt;/li&gt;
&lt;li&gt;i번째 데이터를 고르는 순서에 따라 확률 과정 (stochastic process)이 결정됩니다.&lt;/li&gt;
&lt;li&gt;gradient descent method가 아닙니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reference:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://projecteuclid.org/euclid.aoms/1177729586&#34;&gt;[Robibins-Monro&amp;rsquo;51]&lt;/a&gt;: H. Robbins and S. Monro. A Stochastic Approximation Method. Ann. Math. Statist. 22 (1951), no. 3, 400&amp;ndash;407.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면, batch gradient method로 넘어가봅시다. 일정 묶음의 수만큼 데이터를 확인하고, loss를 계산하여 risk를 모델 가중치 변화에 적용 시킵니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;batch gradient method: $w_{k+1} = w_k - \alpha_k \nabla R_n(w_k)$&lt;/li&gt;
&lt;li&gt;$w_{k+1} = w_k - \frac {\alpha_k}{n} \sum _{i=1}^{n}{\nabla f_i(w_k)}$

&lt;ul&gt;
&lt;li&gt;계산량이 늘어나게 됩니다.&lt;/li&gt;
&lt;li&gt;다양한 최적화 알고리즘을 선택하여 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;각 배치 별로 병렬처리가 가능해집니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 왜 stochastic gradient (SG) 기법이 더 탁월하다고 볼 수 있을까요? &lt;strong&gt;여기서 Risk ($R$)를 최적하 하기 위한 stochastic 기법과 batch 기법의 계산량의 상호보완적인 내용을 짚고 넘어가야 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;sg-bg&#34;&gt;SG &amp;gt; BG&lt;/h3&gt;

&lt;p&gt;stochastic gradient (SG) 기법은 batch 기법보다 더 효율적입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;생각해 볼 문제 #1

&lt;ul&gt;
&lt;li&gt;만약 집합 S의 10개의 복사본으로 데이터가 구성된다면,&lt;/li&gt;
&lt;li&gt;batch 기법으로 수행한다면 SG 기법의 경우보다 10배의 계산량이 요구됩니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;생각해 볼 문제 #2

&lt;ul&gt;
&lt;li&gt;데이터를 구성할 때, training set (40%), test set (30%), validation set (30%) 식으로 보통 구성합니다.&lt;/li&gt;
&lt;li&gt;20%, 10%, 혹은 1% 이런식의 구성은 의미가 없을까요?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, slide#9를 보면 LBFGS와 SGD의 실질적인 비교 결과를 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;LBFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;quasi-newton method와 유사한 최적화 기법입니다.&lt;/li&gt;
&lt;li&gt;제한된 메모리를 가진 컴퓨터에서 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 알고리즘을 근사화 (approximation)시킨 기법입니다.&lt;/li&gt;
&lt;li&gt;기계 학습에서 파라미터 추정 (parameter estimation)에서 많이 쓰입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Slide#9에서, 초기 과정에서 SGD가 LBFGS보다 월등히 빠르게 수렴하는 것을 확인 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Slide#10에서는 Quadratic One-Dimensional example을 소개하고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{x \in \Re}\sum _{i=1}^{m} {(a_i x - b_i)}^{2} $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 예제에서 처럼 혼동되는 구역 (region of confusion)에서 학습 모델 $w_k$를 가지고, 목표로 하는 리스크 $R_n$를 감소시키는 것은 어려운 문제입니다.&lt;/p&gt;

&lt;p&gt;초기에, gradient가 감소세를 보이면, gradient의 분산 (variance)이 혼동되는 구역에서 수렴을 방해합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$E[R&lt;em&gt;n(w&lt;/em&gt;{k+1})-R&lt;em&gt;n(w&lt;/em&gt;{k})]$ \le - \alpha_k&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Unfolding Computational Graphs</title>
      <link>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</link>
      <pubDate>Thu, 02 Jun 2016 00:59:05 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-1-unfolding-computational-graphs&#34;&gt;10.1 Unfolding Computational Graphs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Classical Dynamic System&lt;/strong&gt;:
$ S^{ (t) }=f(s^{ (t-1) };\theta ) $, 여기서 $s^{(t)}$ 는 시스템의 상태를 나타낸다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dynamical system driven by an external signal&lt;/strong&gt; $ x^{(t)} $:
$ S^{ (t) }=f(s^{ (t-1) }, x^{(t)} ;\theta ) $&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) 은 다양한 방법으로 만들수 있다. 대부분은 feedforward neural network로 간주되며, recurrence (재귀표현)를 포함하고 있다면 Recurrent Neural Networks (RNN) 이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;앞서 나온 &lt;strong&gt;Dynamical System&lt;/strong&gt; 식을 이용해, 다음과 같이 유사한 형태의 식으로 RNN의 hidden unit을 정의한다.
$$ h^{(t)} = f(h^{ (t-1) }, x^{(t)} ;\theta ) $$&lt;/p&gt;

&lt;p&gt;예를 들어, RNN이 과거 데이터를 학습하고, 미래를 예측하는 일을 수행한다고 하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;입력: $ x^{(t)}$ (시점 $t$ 까지의 입력)&lt;/li&gt;
&lt;li&gt;종합: $ h^{(t)}$ (정보 손실이 있는 종합된 내용)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 과정을 통해 과거 정보에서 선택적으로 필요한 정보만 유지하여 종합한다. 예를 들어, RNN이 통계적 언어 모델링을 통해, 과거의 단어들을 바탕으로 다음에 나올 단어를 예측한다. 이를 위해, 시점 (time step) $t$ 까지 모든 입력을 다 기억할 필요는 없다. 일정한 정보만으로도 문장의 나머지 단어들을 예측하기에 충분하다.&lt;/p&gt;

&lt;p&gt;RNN을 그림으로 묘사하는 두가지 방법이 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph&lt;/code&gt;: 모든 기능을 하나의 노드로만 표현.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;: 각 기능들이 각각의 노드로 표현. Unfolded 표현은 sequence 길이와 연관된 크기를 가진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unfolding 과정은 다음과 같은 장점을 지닌다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sequence 길이와 상관없이, 학습된 모델은 항상 같은 입력 크기를 가진다.&lt;/li&gt;
&lt;li&gt;같은 파라미터를 사용하는 전이 함수 (transition function) $f$ 를 사용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두가지 요인 때문에, 각 시점마다 $g^{(t)}$ 를 개별적으로 학습시키지 않아도 된다. 같은 파리미터가 공유되기 때문에, 단일 모델 $f$ 가 모든 sequence 길이와 모든 시점에서 동작한다.&lt;/p&gt;

&lt;p&gt;단일화, 공유되는 모델 학습은 일반화를 가능하게 한다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;학습 데이터상의 sequence 길이에 무관하다.&lt;/li&gt;
&lt;li&gt;적은 학습 데이터로도 예측이 가능하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두가지 RNN 표현법은 다음과 같이 각자의 용도가 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph (recurrent graph)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;간단명료하다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;각 단계에서 계산 수행을 분명하게 기술한다.&lt;/li&gt;
&lt;li&gt;진행 방향에 따라 아이디어를 묘사하기 쉽다.&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Forward): output과 loss의 계산&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Backward): gradient 계산&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning in a Nutshell: Core Concepts</title>
      <link>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</link>
      <pubDate>Sat, 23 Apr 2016 16:58:51 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Original post&lt;/a&gt; is written by Tim Dettmers&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall&#34;&gt;Parallel ForAll&lt;/a&gt; 에 작성하는 시리즈 중 첫 글이며, &lt;a href=&#34;https://developer.nvidia.com/deep-learning&#34;&gt;딥 러닝&lt;/a&gt;에 대해 직관적이고 가볍게 소개하고자 한다. 본 포스트는 딥 러닝의 가장 중요한 개념을 다루고 있으며, 수학적 이론 지식보다 기본적인 개념의 전달을 목적으로 한다. 수식과 함께라면 더 깊은 이해가 가능하겠지만, 이 포스트는 비유와 그림을 통해 더욱 이해하기 쉬운 직관적인 개요를 전달하고자 한다.
이 글들은 단어사전식으로 작성되어 딥러닝 개념을 위한 참고자료로 사용 될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Part 1&lt;/a&gt;에서는 딥 러닝의 중요한 개념에 대해서 소개한다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training&#34;&gt;Part 2&lt;/a&gt;에서는 딥 러닝의 역사적 배경과 학습 과정, 알고리즘, 실용적인 기법 등을 살펴본다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-sequence-learning&#34;&gt;Part 3&lt;/a&gt;에서는 자연어 번역을 위한 sequence learning 에 대해 알아본다. recurrent neural networks, LSTMs, encoder-decoder system을 포함한다.&lt;/p&gt;

&lt;h2 id=&#34;core-concepts-핵심-개념&#34;&gt;Core Concepts (핵심 개념)&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;machine-learning-기계-학습&#34;&gt;Machine Learning (기계 학습)&lt;/h3&gt;

&lt;p&gt;기계 학습을 통해 우리는 (1) 데이터를 획득하여, (2) 데이터를 통해 모델을 학습하고, (3) 학습된 모델을 이용하여, 새로운 데이터에 대해 예측한다. 모델을 &lt;a href=&#34;http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training#training&#34;&gt;학습&lt;/a&gt;하는 과정은 새롭고, 익숙치 않은 자료를 하나씩 살펴보고 배움을 얻는 과정과도 같다. 각 단계마다, 모델은 예측을 하고, 얼마나 정확히 예측하였는지에 대해 피드백을 받는다. 이 피드백은 정답으로부터 얼만큼 차이가 나는지 등과 같은 방법을 통해 측정 가능한 오류(error)를 통해, 예측을 더 정확하게 하는데 사용된다.&lt;/p&gt;

&lt;p&gt;학습과정은 종종 파라미터 공간 (parameter space)에서 후진-전진이 반복는 게임이다: 만약 당신이 좋은 예측 결과를 얻기 위해 모델의 파라미터를 수정한다면, 이전에 제대로 예측했던 것도 수정 이후, 틀리게 예측될 수도 있다. 우수한 예측 성능을 가진 모델을 학습한다는 것은 많은 반복 작업이 필요할 것이다. 이런 반복적인 예측-수정의 과정은 예측 결과가 더 이상 발전이 없을 때 까지 반복한다.&lt;/p&gt;

&lt;h3 id=&#34;feature-engineering-특징-공학&#34;&gt;Feature Engineering (특징 공학)&lt;/h3&gt;

&lt;p&gt;특징 공학은 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/#machine-learning&#34;&gt;기계 학습&lt;/a&gt; 모델로 하여금 데이터들로 부터 클래스들을 쉽게 구분 할 수 있도록 도와주는 유용한 패턴을 추출 하는 것이다. 예를 들어,사진으로 부터 땅과 물고기를 구분하는 것을 초록색과 푸른색 픽셀의 수를 이용한다고 하자. 이런 특징은 기계 학습 모델에 도움이 된다. 좋은 분류를 위해 클래스의 갯수가 제한되어 있기때문에 좋은 분류가 가능하다.&lt;/p&gt;

&lt;p&gt;특징 공학은 대부분의 예측 분야에서 좋은 성능을 얻기위해 요구되는 가장 중요한 기술이다. 하지만, 다른 데이터 셋과 다른 종류의 데이터들은 각자 다른 특징 공학 기법이 필요하기에, 최고의 특징 공학 기술을 습득하고 마스터하기엔 어렵다. 특징 공학은 과학이라기 보다 예술의 경지에 가깝다. 특정 데이터 셋에서 추출된 특징은 종종 다른 데이터 셋에서는 적용되지 않는다. (위 예제에서 계속하여, 다음 사진이 오직 육지 동물만 포함하는 경우). 특징 공학이 어렵다는 점과 많은 노력이 요구되는 점이 &lt;strong&gt;자동으로 특징을 학습할 수 있는 알고리즘&lt;/strong&gt;을 찾게 되는 가장 큰 이유이다.&lt;/p&gt;

&lt;p&gt;물체 인식이나 음성 인식과 같은 분야의 영역이 특징 학습을 통해 자동화되고 있지만, 특징 공학은 &lt;a href=&#34;http://blog.kaggle.com/2014/08/01/learning-from-the-best/&#34;&gt;kaggle 기계 학습 대회의 어려운 여러 분야에서 가장 효율적인 방법&lt;/a&gt;으로  여전히 지속 될 것이다.&lt;/p&gt;

&lt;h3 id=&#34;feature-learning-특징-학습&#34;&gt;Feature Learning (특징 학습)&lt;/h3&gt;

&lt;p&gt;특징 학습 알고리즘은 서로 다른 범주(클래스)의 분류를 위한 가장 중요하며, 공통적으로 나타나는 패턴을 찾는다. 그리고 특징을 자동으로 추출하여 분류나 회귀 문제에 적용된다. 특징 학습은 특징 공학처럼 알고리즘을 통해 자동으로 수행되는 것 처럼 생각된다. 딥러닝에서는 convolutional layer가 예외적으로 이미지에서 좋은 특징을 찾는데 탁월한 능력을 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/11/hierarchical_features.png&#34; alt=&#34;&#34; /&gt;
Figure 1: 딥 러닝 알고리즘으로 부터 학습된 계층형 특징들.&lt;/p&gt;

&lt;h4 id=&#34;deep-learning-딥-러닝&#34;&gt;Deep Learning (딥 러닝)&lt;/h4&gt;

&lt;h3 id=&#34;fundamental-concepts-기본-개념&#34;&gt;Fundamental Concepts (기본 개념)&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;logistic-regression&#34;&gt;Logistic Regression ()&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neural-network-인공-신경망&#34;&gt;Artificial Neural Network (인공 신경망)&lt;/h4&gt;

&lt;h4 id=&#34;unit&#34;&gt;Unit&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neuron&#34;&gt;Artificial Neuron&lt;/h4&gt;

&lt;h4 id=&#34;activation-function&#34;&gt;Activation Function&lt;/h4&gt;

&lt;h4 id=&#34;layer&#34;&gt;Layer&lt;/h4&gt;

&lt;h3 id=&#34;convolutional-deep-learning&#34;&gt;Convolutional Deep Learning&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;convolution&#34;&gt;Convolution&lt;/h4&gt;

&lt;h4 id=&#34;pooling-subsampling&#34;&gt;Pooling / Subsampling&lt;/h4&gt;

&lt;h4 id=&#34;convolutional-neural-network-cnn&#34;&gt;Convolutional Neural Network (CNN)&lt;/h4&gt;

&lt;h4 id=&#34;inception&#34;&gt;Inception&lt;/h4&gt;

&lt;h3 id=&#34;conclusion-to-part-1&#34;&gt;Conclusion to Part 1&lt;/h3&gt;

&lt;hr /&gt;
</description>
    </item>
    
  </channel>
</rss>