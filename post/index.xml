<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Taegyun Jeon</title>
    <link>https://tgjeon.github.io/post/</link>
    <description>Recent content in Posts on Taegyun Jeon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Taegyun Jeon</copyright>
    <lastBuildDate>Tue, 23 Aug 2016 12:54:32 +0900</lastBuildDate>
    <atom:link href="https://tgjeon.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>RNNs in Tensorflow, A Practical Guide and Undocumented Features</title>
      <link>https://tgjeon.github.io/post/rnns-in-tensorflow/</link>
      <pubDate>Tue, 23 Aug 2016 12:54:32 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnns-in-tensorflow/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/&#34;&gt;Original post&lt;/a&gt; is written by Denny Britz (Google Brain team).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 위 내용을 한글로 정리한 내용입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이전 &lt;a href=&#34;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&#34;&gt;튜토리얼&lt;/a&gt;에서, Recurrent Neural Networks (RNNs)에 대한 이론들에 대해서 살펴보고, 간단한 RNN을 기초부터 만들어보는 과정을 진행했습니다. 이 과정들은 유용했지만, 현업에선 RNNs에 대한 고수준의 기초요소들을 제공하는 Tensorflow와 같이 라이브러리를 사용합니다.&lt;/p&gt;

&lt;p&gt;RNNs을 함수 호출해서 사용하는 것처럼 쉽게 쓰면 좋겠지만, 현실은 만만치 않습니다. 이번 포스트에서는 Tensorflow를 이용하여 RNNs을 실질적으로 동작시켜보고, 특히 공식 사이트에서 문서화 되지 않은 기능들에 대해 다뤄보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;본 포스트는 Jupyer 노트북이 포함된 Github 저장소에 아래와 같은 예제들을 다루고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 사용하기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/batching_padding.ipynb&#34;&gt;Batching과 Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb&#34;&gt;Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/bidirectional_rnn.ipynb&#34;&gt;Bidirectional Dynamic RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/rnn_cell_wrappers.py.ipynb&#34;&gt;RNN Cells과 Cell Wrappers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/loss_masking.py.ipynb&#34;&gt;Masking the Loss&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;데이터-전처리-tf-sequenceexample-사용하기&#34;&gt;데이터 전처리: tf.SequenceExample 사용하기&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb&#34;&gt;tf.SequenceExample 주피터 노트북을 확인하세요!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNNs은 순차적인 데이터를 사용하며, 이 순차적인 데이터는 입력과 출력을 여러 시간 스텝으로 구성되어 있습니다. Tensorflow는 순차적 데이터: &lt;a href=&#34;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto&#34;&gt;tf.SequenceExample&lt;/a&gt; 를 다루기 위해 &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;프로토콜 버퍼&lt;/a&gt;가 정의되어 있습니다.&lt;/p&gt;

&lt;p&gt;사용자는 Python/Numpy 배열로부터 직접 데이터를 불러올 수 있습니다. 하지만, &lt;code&gt;tf.SequenceExample&lt;/code&gt;가 더 관심 대상이므로 이것을 사용해보도록 합시다. 이 자료 구조는 비순차적 특징 (non-sequential features)은 &lt;code&gt;&amp;quot;context&amp;quot;&lt;/code&gt;로, 순차적 특징 (sequential features)은 &lt;code&gt;&amp;quot;feature_lists&amp;quot;&lt;/code&gt;로 구성됩니다. 장황하긴 하지만, 이것이 주는 장점은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;쉬운 &lt;a href=&#34;https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#distributed-tensorflow&#34;&gt;분산 학습&lt;/a&gt;&lt;/strong&gt;:&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recurrent Neural Networks</title>
      <link>https://tgjeon.github.io/post/rnn_rnn/</link>
      <pubDate>Tue, 05 Jul 2016 05:33:52 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_rnn/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-2-recurrent-neural-networks-rnns&#34;&gt;10.2 Recurrent Neural Networks (RNNs)&lt;/h3&gt;

&lt;p&gt;앞선 &lt;a href=&#34;https://tgjeon.github.io/post/rnn_unfolding_computational_graph/&#34;&gt;포스트&lt;/a&gt;에서 설명한 그래프 풀기 (graph unrolling)과 파라미터 공유 (parameter sharing)을 통해 다양한 형태의 recurrent neural networks를 디자인 할 수 있다.&lt;/p&gt;

&lt;p&gt;Recurrent Neural Networks의 중요한 디자인 패턴들은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;그림 10.3

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (h^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.4

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden-Output (hidden/output unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h, o), (o, L), (L, y), (o^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;그림 10.5

&lt;ul&gt;
&lt;li&gt;Input (매 시점 t 마다), Output (최종 시점 $\tau$에만), Hidden (hidden unit간 연결)&lt;/li&gt;
&lt;li&gt;$(x, h), (h^{\tau}, o^{\tau}), (o^\tau, L^\tau), (L^\tau, y^\tau)$ (여기서 (a, b)는 a와 b가 연결됨을 의미)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;처음 소개된 그림 10.3과 같은 형태는, recurrent neural networks의 가장 대표적인 형태이며, 이번 내용에서 가장 많이 설명될 것이다. 이와 같은 형태는 Turing machine과 같은 계산 과정을 통해 수행된다고 생각하면 된다. 시점 $t$의 갯수 (점근적 선형으로 증가하는) 만큼의 입력을 받아 해당 시점 이후의 출력을 가진다. 이는 근사치가 아닌 정확한 계산 결과이며 이산값으로 나타낸다.&lt;/p&gt;

&lt;p&gt;그림 10.3에서 동작하는 forward propagation 수식을 살펴보자. 개념적인 이야기를 다루고 있기 때문에, activation function, loss function, output 형태를 언급하지 않고 있다. 따라서, activation function은 $\tanh$로 두고 output은 discrete 값을 가정한다. 그리고 RNN 모델은 단어나 문자를 예측하는데 사용된다고 가정하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;output $o$는 각 이산값에 대해 정규화되지 않은 확률 분포로 나타낸다.&lt;/li&gt;
&lt;li&gt;최종 예측값은 $\hat{y}$는 출력 $o$에 대해 softmax()를 적용하여 정규화된 확률 값을 가진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forward propagation은 다음과 같이 동작한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Initial state: $h^{(0)}$로 부터 시작.&lt;/li&gt;
&lt;li&gt;Input-to-hidden ($U$)과 hidden-to-hidden ($W$): $a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$&lt;/li&gt;
&lt;li&gt;Activation: $h^{(t)} = \tanh(a^{(t)})$&lt;/li&gt;
&lt;li&gt;hidden-to-output ($V$): $o^{(t)} = c + Vh^{(t)}$&lt;/li&gt;
&lt;li&gt;Normailized discrete output: ${\hat{y}}^{(t)} = softmax(o^{(t)})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 모델은 입력 sequence와 출력 sequence의 길이가 동일하다. 전체 입,출력 sequence에 대한 loss는 각 시점 (time steps)마다의 loss를 모두 더한 것과 같다.&lt;/p&gt;

&lt;p&gt;$ L(${ $x^{(1)}, &amp;hellip;, x^{(\tau)} $}, { $y{(1)}, &amp;hellip;, y^{(\tau)} $}$)$&lt;/p&gt;

&lt;p&gt;$= \sum _{t}{L^{(t)}} $&lt;/p&gt;

&lt;p&gt;$= -\sum _{t}{\log{p}} _{model} (y^{(t)} | ${ $x^{(1)}, &amp;hellip;, x^{(t)} $}$)$&lt;/p&gt;

&lt;p&gt;$L^{(t)} $가 입력 $x^{(1)}, &amp;hellip;, x^{(t)}$이 주어졌을 때, 출력 $y^{(t)}$에 대한 negative log-likelihood라고 하자.
gradient를 계산하는 과정은 각 시점 (time steps)에 대해 수행된다. 수행 시간은 $O(\tau)$이며, 병렬처리가 불가능하다.
이 모델은 강력하지만 학습 과정에서 많은 계산량을 요구한다. 이를 &lt;em&gt;back-propagation through time&lt;/em&gt; 혹은 &lt;em&gt;BPTT&lt;/em&gt; 라고 한다.&lt;/p&gt;

&lt;h3 id=&#34;10-2-1-teacher-forcing-and-networks-with-output-recurrence&#34;&gt;10.2.1 Teacher Forcing and Networks with Output Recurrence&lt;/h3&gt;

&lt;p&gt;그림 10.4에서 보여주고 있는 RNN모델은 hidden-to-hidden 연결성이 부족하기 때문에 강력하지 않다. hidden-to-hidden 연결이 없기 때문에, output 유닛이 과거 네트워크의 모든 정보를 가지고 미래를 예측해야한다. 그래서, output 유닛은 명백하게 학습 데이터의 타겟에 대해 학습된다. 사용자는 과거 모든 입력의 기록을 모아둘 필요가 없어진다.&lt;/p&gt;

&lt;p&gt;hidden-to-hidden 연결을 제거함으로 얻는 이득은, 시점 $t$에서 예측하는 데 필요한 loss의 계산이 모든 시점 $t$에 대한 관계성이 없어진다. 따라서 학습 단계는 병렬처리 가능하며, 각 시점 $t$에서의 gradient 계산은 독립적으로 수행 가능하다.&lt;/p&gt;

&lt;p&gt;output에서 바로 모델이 학습 하는 경우를 teacher forcing 이라고 한다. 이는 maximum likelihood criterion을 따르며, ground truth $\hat(y)^{(t)}$가 $t+1$ 시점의 입력으로 사용된다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;두 시점의 sequence를 예를 들어보면, conditional maximum likelihood criterion은 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ \log{p} (y^{(1)}, y^{(2)} | x^{(1)}, x^{(2)})$&lt;/p&gt;

&lt;p&gt;$ = \log{p} (y^{(2)} | y^{(1)}, x^{(1)}, x^{(2)})  +  \log{p} (y^{(1)} | x^{(1)}, x^{(2)}) $&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Gradient Methods</title>
      <link>https://tgjeon.github.io/post/stochastic_gradient_methods/</link>
      <pubDate>Wed, 29 Jun 2016 10:49:16 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/stochastic_gradient_methods/</guid>
      <description>

&lt;h1 id=&#34;stochastic-gradient-methods-for-large-scale-machine-learning-part-1&#34;&gt;Stochastic Gradient Methods for Large-Scale Machine Learning (Part 1)&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Original presentation materials: &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-2.pdf&#34;&gt;Part2&lt;/a&gt;, &lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-3.pdf&#34;&gt;Part3&lt;/a&gt; is written by Leon Bottou (Facebook AI Research), Frank E. Curtis (Lehigh University), and Jorge Nocedal (Northwestern University).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 ICML 2016 Tutorial 중 &amp;ldquo;Stochastic Gradient Methods for Large-Scale Machine Learning&amp;rdquo; 의 내용을 한글로 정리한 포스트입니다. 해당 발표자료는 위 링크를 참고하여 확인하시기 바랍니다. 원 튜토리얼 자료와 같이 보시는 것을 권합니다.&lt;/p&gt;

&lt;p&gt;해당 튜토리얼은 &lt;a href=&#34;http://arxiv.org/abs/1606.04838&#34;&gt;&amp;ldquo;Optimization Methods for Large-Scale Machine Learning&amp;rdquo;&lt;/a&gt;, L. Bottou, F.E. Curtis, J. Nocedal, Prepared for SIAM Review 논문을 요약한 내용이라고 합니다. 다 자세한 내용을 보고싶으신 분은 위 논문을 참고하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;튜토리얼의-목표&#34;&gt;튜토리얼의 목표&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Stochastic gradient (SG) 방법에 대해 알아본다.&lt;/li&gt;
&lt;li&gt;SG는 왜 중요해질까?&lt;/li&gt;
&lt;li&gt;핵심 매커니즘은 무엇인가?&lt;/li&gt;
&lt;li&gt;convex와 non-convex의 경우에 어떻게 행동한다고 할수 있는가?&lt;/li&gt;
&lt;li&gt;SG를 향상 시키기위해서 어떤 노력들이 있었는가?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;튜토리얼의-구성&#34;&gt;튜토리얼의 구성&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Motivation for the stochastic gradient (SG) method&lt;/li&gt;
&lt;li&gt;Analysis of SG&lt;/li&gt;
&lt;li&gt;Beyond SG&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;문제-정의-problem-statement&#34;&gt;문제 정의 (Problem statement)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;학습 데이터가 주어집니다. training set: $ {(x_1, y_1), &amp;hellip;, (x_n, y_n)} $&lt;/li&gt;
&lt;li&gt;손실 함수가 주어집니다. loss function: $ \ell(h,y) $

&lt;ul&gt;
&lt;li&gt;여기서 우리의 예측이 실제 학습 데이터의 label인 $y$와 얼마나 다른지 측정합니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;예측 함수는 $h(x;w)$ 입니다.

&lt;ul&gt;
&lt;li&gt;$x$는 입력 데이터 (input data), $w$는 학습 모델의 가중치 (weights of model) 입니다. 모델 $w$가 입력 $x$을 받아 예측 결과 $\hat {y}$를 출력으로 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 우리의 목표는 가장 최선의 예측을 하는 것입니다. 주어진 학습 데이터에 대해 예측 손실을 최소화하는 모델을 만들어서 이 목표를 달성하고자 합니다. 하나의 수식으로 표현하면 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{w}{\frac {1}{n} \sum _{i=1}^{n}{\ell(h(x_i; w), y_i)} } $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 학습 데이터에 대해 예측을 하고, 각 학습 데이터에 대한 예측이 학습 데이터의 label인 $y$와 차이가 적게 나타도록 하는 $w$가 우리의 학습 모델이 됩니다. 충분한 학습 데이터는 경험이라고 표현 할 수 있습니다. 우리의 학습 모델이 얼마나 큰 위험 요소 (Risk)를 가지고 있는지 표현해봅시다. 여기서 $f$는 손실 함수 (loss function) 입니다. 경험적 위험요소 (empirical risk)는 아래와 같이 표현됩니다. 각 학습 데이터 마다 loss를 계산해서 평균내어 risk로 나타냅니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터가 충분히 모였다면 데이터에 대한 확률 분포가 존재합니다. 이 때, 우리의 학습 데이터를 랜덤 변수 $\xi=(x_i, y_i)$ 로 표현합니다. 그렇다면 위험요소 (risk)는 기대값으로 나타낼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;expected risk: $R(w) = E[f(w;x_i)] $&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;stochastic-gradient-method-vs-batch-gradient-method&#34;&gt;Stochastic Gradient Method vs Batch Gradient Method&lt;/h3&gt;

&lt;p&gt;이전에 표현했던 empirical risk minimization을 살펴봅시다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;empirical risk: $R_n(w) = \frac{1}{n} \sum _{i=1}^{n}{f_i(w)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;데이터를 하나씩 관찰하면서, 모델의 가중치는 아래와 같은 수식을 통해 변화됩니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;weight update: $w_{k+1} = w_k - \alpha_k \nabla f_i(w_k),$ where $i \in$ {$1,&amp;hellip;,n$} choose at random

&lt;ul&gt;
&lt;li&gt;단순 반복을 통해 가능합니다. 데이터 1개씩만 보고 변화율 (gradient)을 변경합니다.&lt;/li&gt;
&lt;li&gt;i번째 데이터를 고르는 순서에 따라 확률 과정 (stochastic process)이 결정됩니다.&lt;/li&gt;
&lt;li&gt;gradient descent method가 아닙니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reference:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://projecteuclid.org/euclid.aoms/1177729586&#34;&gt;[Robibins-Monro&amp;rsquo;51]&lt;/a&gt;: H. Robbins and S. Monro. A Stochastic Approximation Method. Ann. Math. Statist. 22 (1951), no. 3, 400&amp;ndash;407.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면, batch gradient method로 넘어가봅시다. 일정 묶음의 수만큼 데이터를 확인하고, loss를 계산하여 risk를 모델 가중치 변화에 적용 시킵니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;batch gradient method: $w_{k+1} = w_k - \alpha_k \nabla R_n(w_k)$&lt;/li&gt;
&lt;li&gt;$w_{k+1} = w_k - \frac {\alpha_k}{n} \sum _{i=1}^{n}{\nabla f_i(w_k)}$

&lt;ul&gt;
&lt;li&gt;계산량이 늘어나게 됩니다.&lt;/li&gt;
&lt;li&gt;다양한 최적화 알고리즘을 선택하여 사용할 수 있습니다.&lt;/li&gt;
&lt;li&gt;각 배치 별로 병렬처리가 가능해집니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 왜 stochastic gradient (SG) 기법이 더 탁월하다고 볼 수 있을까요? &lt;strong&gt;여기서 Risk ($R$)를 최적하 하기 위한 stochastic 기법과 batch 기법의 계산량의 상호보완적인 내용을 짚고 넘어가야 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;sg-bg&#34;&gt;SG &amp;gt; BG&lt;/h3&gt;

&lt;p&gt;stochastic gradient (SG) 기법은 batch 기법보다 더 효율적입니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;생각해 볼 문제 #1

&lt;ul&gt;
&lt;li&gt;만약 집합 S의 10개의 복사본으로 데이터가 구성된다면,&lt;/li&gt;
&lt;li&gt;batch 기법으로 수행한다면 SG 기법의 경우보다 10배의 계산량이 요구됩니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;생각해 볼 문제 #2

&lt;ul&gt;
&lt;li&gt;데이터를 구성할 때, training set (40%), test set (30%), validation set (30%) 식으로 보통 구성합니다.&lt;/li&gt;
&lt;li&gt;20%, 10%, 혹은 1% 이런식의 구성은 의미가 없을까요?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://www.icml.cc/2016/tutorials/part-1.pdf&#34;&gt;Part1&lt;/a&gt;, slide#9를 보면 LBFGS와 SGD의 실질적인 비교 결과를 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;LBFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;quasi-newton method와 유사한 최적화 기법입니다.&lt;/li&gt;
&lt;li&gt;제한된 메모리를 가진 컴퓨터에서 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 알고리즘을 근사화 (approximation)시킨 기법입니다.&lt;/li&gt;
&lt;li&gt;기계 학습에서 파라미터 추정 (parameter estimation)에서 많이 쓰입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Slide#9에서, 초기 과정에서 SGD가 LBFGS보다 월등히 빠르게 수렴하는 것을 확인 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;Slide#10에서는 Quadratic One-Dimensional example을 소개하고 있습니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$ \min _{x \in \Re}\sum _{i=1}^{m} {(a_i x - b_i)}^{2} $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 예제에서 처럼 혼동되는 구역 (region of confusion)에서 학습 모델 $w_k$를 가지고, 목표로 하는 리스크 $R_n$를 감소시키는 것은 어려운 문제입니다.&lt;/p&gt;

&lt;p&gt;초기에, gradient가 감소세를 보이면, gradient의 분산 (variance)이 혼동되는 구역에서 수렴을 방해합니다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$E[R&lt;em&gt;n(w&lt;/em&gt;{k+1})-R&lt;em&gt;n(w&lt;/em&gt;{k})]$ \le - \alpha_k&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Unfolding Computational Graphs</title>
      <link>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</link>
      <pubDate>Thu, 02 Jun 2016 00:59:05 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/rnn_unfolding_computational_graph/</guid>
      <description>

&lt;h3 id=&#34;chapter-10-sequence-modeling-recurrent-and-recursive-nets&#34;&gt;Chapter 10. Sequence Modeling: Recurrent and Recursive Nets&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.deeplearningbook.org&#34;&gt;Original book chapter&lt;/a&gt; is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &amp;ldquo;Deep Learning published by Mit Press (2016)&amp;rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;10-1-unfolding-computational-graphs&#34;&gt;10.1 Unfolding Computational Graphs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Classical Dynamic System&lt;/strong&gt;:
$ S^{ (t) }=f(s^{ (t-1) };\theta ) $, 여기서 $s^{(t)}$ 는 시스템의 상태를 나타낸다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dynamical system driven by an external signal&lt;/strong&gt; $ x^{(t)} $:
$ S^{ (t) }=f(s^{ (t-1) }, x^{(t)} ;\theta ) $&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) 은 다양한 방법으로 만들수 있다. 대부분은 feedforward neural network로 간주되며, recurrence (재귀표현)를 포함하고 있다면 Recurrent Neural Networks (RNN) 이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;앞서 나온 &lt;strong&gt;Dynamical System&lt;/strong&gt; 식을 이용해, 다음과 같이 유사한 형태의 식으로 RNN의 hidden unit을 정의한다.
$$ h^{(t)} = f(h^{ (t-1) }, x^{(t)} ;\theta ) $$&lt;/p&gt;

&lt;p&gt;예를 들어, RNN이 과거 데이터를 학습하고, 미래를 예측하는 일을 수행한다고 하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;입력: $ x^{(t)}$ (시점 $t$ 까지의 입력)&lt;/li&gt;
&lt;li&gt;종합: $ h^{(t)}$ (정보 손실이 있는 종합된 내용)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 과정을 통해 과거 정보에서 선택적으로 필요한 정보만 유지하여 종합한다. 예를 들어, RNN이 통계적 언어 모델링을 통해, 과거의 단어들을 바탕으로 다음에 나올 단어를 예측한다. 이를 위해, 시점 (time step) $t$ 까지 모든 입력을 다 기억할 필요는 없다. 일정한 정보만으로도 문장의 나머지 단어들을 예측하기에 충분하다.&lt;/p&gt;

&lt;p&gt;RNN을 그림으로 묘사하는 두가지 방법이 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph&lt;/code&gt;: 모든 기능을 하나의 노드로만 표현.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;: 각 기능들이 각각의 노드로 표현. Unfolded 표현은 sequence 길이와 연관된 크기를 가진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unfolding 과정은 다음과 같은 장점을 지닌다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sequence 길이와 상관없이, 학습된 모델은 항상 같은 입력 크기를 가진다.&lt;/li&gt;
&lt;li&gt;같은 파라미터를 사용하는 전이 함수 (transition function) $f$ 를 사용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두가지 요인 때문에, 각 시점마다 $g^{(t)}$ 를 개별적으로 학습시키지 않아도 된다. 같은 파리미터가 공유되기 때문에, 단일 모델 $f$ 가 모든 sequence 길이와 모든 시점에서 동작한다.&lt;/p&gt;

&lt;p&gt;단일화, 공유되는 모델 학습은 일반화를 가능하게 한다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;학습 데이터상의 sequence 길이에 무관하다.&lt;/li&gt;
&lt;li&gt;적은 학습 데이터로도 예측이 가능하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두가지 RNN 표현법은 다음과 같이 각자의 용도가 있다.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Folded graph (recurrent graph)&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;간단명료하다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unfolded graph&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;각 단계에서 계산 수행을 분명하게 기술한다.&lt;/li&gt;
&lt;li&gt;진행 방향에 따라 아이디어를 묘사하기 쉽다.&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Forward): output과 loss의 계산&lt;/li&gt;
&lt;li&gt;정보의 흐름 (Backward): gradient 계산&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning in a Nutshell: Core Concepts</title>
      <link>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</link>
      <pubDate>Sat, 23 Apr 2016 16:58:51 +0900</pubDate>
      
      <guid>https://tgjeon.github.io/post/deep_learning_in_a_nut_shell_core_concept/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Original post&lt;/a&gt; is written by Tim Dettmers&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 포스트는 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall&#34;&gt;Parallel ForAll&lt;/a&gt; 에 작성하는 시리즈 중 첫 글이며, &lt;a href=&#34;https://developer.nvidia.com/deep-learning&#34;&gt;딥 러닝&lt;/a&gt;에 대해 직관적이고 가볍게 소개하고자 한다. 본 포스트는 딥 러닝의 가장 중요한 개념을 다루고 있으며, 수학적 이론 지식보다 기본적인 개념의 전달을 목적으로 한다. 수식과 함께라면 더 깊은 이해가 가능하겠지만, 이 포스트는 비유와 그림을 통해 더욱 이해하기 쉬운 직관적인 개요를 전달하고자 한다.
이 글들은 단어사전식으로 작성되어 딥러닝 개념을 위한 참고자료로 사용 될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts&#34;&gt;Part 1&lt;/a&gt;에서는 딥 러닝의 중요한 개념에 대해서 소개한다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training&#34;&gt;Part 2&lt;/a&gt;에서는 딥 러닝의 역사적 배경과 학습 과정, 알고리즘, 실용적인 기법 등을 살펴본다. &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-sequence-learning&#34;&gt;Part 3&lt;/a&gt;에서는 자연어 번역을 위한 sequence learning 에 대해 알아본다. recurrent neural networks, LSTMs, encoder-decoder system을 포함한다.&lt;/p&gt;

&lt;h2 id=&#34;core-concepts-핵심-개념&#34;&gt;Core Concepts (핵심 개념)&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;machine-learning-기계-학습&#34;&gt;Machine Learning (기계 학습)&lt;/h3&gt;

&lt;p&gt;기계 학습을 통해 우리는 (1) 데이터를 획득하여, (2) 데이터를 통해 모델을 학습하고, (3) 학습된 모델을 이용하여, 새로운 데이터에 대해 예측한다. 모델을 &lt;a href=&#34;http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training#training&#34;&gt;학습&lt;/a&gt;하는 과정은 새롭고, 익숙치 않은 자료를 하나씩 살펴보고 배움을 얻는 과정과도 같다. 각 단계마다, 모델은 예측을 하고, 얼마나 정확히 예측하였는지에 대해 피드백을 받는다. 이 피드백은 정답으로부터 얼만큼 차이가 나는지 등과 같은 방법을 통해 측정 가능한 오류(error)를 통해, 예측을 더 정확하게 하는데 사용된다.&lt;/p&gt;

&lt;p&gt;학습과정은 종종 파라미터 공간 (parameter space)에서 후진-전진이 반복는 게임이다: 만약 당신이 좋은 예측 결과를 얻기 위해 모델의 파라미터를 수정한다면, 이전에 제대로 예측했던 것도 수정 이후, 틀리게 예측될 수도 있다. 우수한 예측 성능을 가진 모델을 학습한다는 것은 많은 반복 작업이 필요할 것이다. 이런 반복적인 예측-수정의 과정은 예측 결과가 더 이상 발전이 없을 때 까지 반복한다.&lt;/p&gt;

&lt;h3 id=&#34;feature-engineering-특징-공학&#34;&gt;Feature Engineering (특징 공학)&lt;/h3&gt;

&lt;p&gt;특징 공학은 &lt;a href=&#34;https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/#machine-learning&#34;&gt;기계 학습&lt;/a&gt; 모델로 하여금 데이터들로 부터 클래스들을 쉽게 구분 할 수 있도록 도와주는 유용한 패턴을 추출 하는 것이다. 예를 들어,사진으로 부터 땅과 물고기를 구분하는 것을 초록색과 푸른색 픽셀의 수를 이용한다고 하자. 이런 특징은 기계 학습 모델에 도움이 된다. 좋은 분류를 위해 클래스의 갯수가 제한되어 있기때문에 좋은 분류가 가능하다.&lt;/p&gt;

&lt;p&gt;특징 공학은 대부분의 예측 분야에서 좋은 성능을 얻기위해 요구되는 가장 중요한 기술이다. 하지만, 다른 데이터 셋과 다른 종류의 데이터들은 각자 다른 특징 공학 기법이 필요하기에, 최고의 특징 공학 기술을 습득하고 마스터하기엔 어렵다. 특징 공학은 과학이라기 보다 예술의 경지에 가깝다. 특정 데이터 셋에서 추출된 특징은 종종 다른 데이터 셋에서는 적용되지 않는다. (위 예제에서 계속하여, 다음 사진이 오직 육지 동물만 포함하는 경우). 특징 공학이 어렵다는 점과 많은 노력이 요구되는 점이 &lt;strong&gt;자동으로 특징을 학습할 수 있는 알고리즘&lt;/strong&gt;을 찾게 되는 가장 큰 이유이다.&lt;/p&gt;

&lt;p&gt;물체 인식이나 음성 인식과 같은 분야의 영역이 특징 학습을 통해 자동화되고 있지만, 특징 공학은 &lt;a href=&#34;http://blog.kaggle.com/2014/08/01/learning-from-the-best/&#34;&gt;kaggle 기계 학습 대회의 어려운 여러 분야에서 가장 효율적인 방법&lt;/a&gt;으로  여전히 지속 될 것이다.&lt;/p&gt;

&lt;h3 id=&#34;feature-learning-특징-학습&#34;&gt;Feature Learning (특징 학습)&lt;/h3&gt;

&lt;p&gt;특징 학습 알고리즘은 서로 다른 범주(클래스)의 분류를 위한 가장 중요하며, 공통적으로 나타나는 패턴을 찾는다. 그리고 특징을 자동으로 추출하여 분류나 회귀 문제에 적용된다. 특징 학습은 특징 공학처럼 알고리즘을 통해 자동으로 수행되는 것 처럼 생각된다. 딥러닝에서는 convolutional layer가 예외적으로 이미지에서 좋은 특징을 찾는데 탁월한 능력을 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/11/hierarchical_features.png&#34; alt=&#34;&#34; /&gt;
Figure 1: 딥 러닝 알고리즘으로 부터 학습된 계층형 특징들.&lt;/p&gt;

&lt;h4 id=&#34;deep-learning-딥-러닝&#34;&gt;Deep Learning (딥 러닝)&lt;/h4&gt;

&lt;h3 id=&#34;fundamental-concepts-기본-개념&#34;&gt;Fundamental Concepts (기본 개념)&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;logistic-regression&#34;&gt;Logistic Regression ()&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neural-network-인공-신경망&#34;&gt;Artificial Neural Network (인공 신경망)&lt;/h4&gt;

&lt;h4 id=&#34;unit&#34;&gt;Unit&lt;/h4&gt;

&lt;h4 id=&#34;artificial-neuron&#34;&gt;Artificial Neuron&lt;/h4&gt;

&lt;h4 id=&#34;activation-function&#34;&gt;Activation Function&lt;/h4&gt;

&lt;h4 id=&#34;layer&#34;&gt;Layer&lt;/h4&gt;

&lt;h3 id=&#34;convolutional-deep-learning&#34;&gt;Convolutional Deep Learning&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;convolution&#34;&gt;Convolution&lt;/h4&gt;

&lt;h4 id=&#34;pooling-subsampling&#34;&gt;Pooling / Subsampling&lt;/h4&gt;

&lt;h4 id=&#34;convolutional-neural-network-cnn&#34;&gt;Convolutional Neural Network (CNN)&lt;/h4&gt;

&lt;h4 id=&#34;inception&#34;&gt;Inception&lt;/h4&gt;

&lt;h3 id=&#34;conclusion-to-part-1&#34;&gt;Conclusion to Part 1&lt;/h3&gt;

&lt;hr /&gt;
</description>
    </item>
    
  </channel>
</rss>