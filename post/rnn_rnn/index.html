<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="theme" content="hugo-academic">
    <meta name="generator" content="Hugo 0.16" />
    <meta name="author" content="Taegyun Jeon">
    <meta name="description" content="Research Scientist in Machine Learning and Biomedical Engineering">

    <link rel="stylesheet" href="https://tgjeon.github.io/css/highlight.min.css">
    <link rel="stylesheet" href="https://tgjeon.github.io/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://tgjeon.github.io/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://tgjeon.github.io/css/academicons.min.css">
    <link rel="stylesheet" href="https://tgjeon.github.io/css/hugo-academic.css">
    


    <link rel="shortcut icon" href="https://tgjeon.github.io/img/favicon.ico" type="image/x-icon">
    <link rel="canonical" href="https://tgjeon.github.io/post/rnn_rnn/">

    <title>Recurrent Neural Networks | Taegyun Jeon</title>

</head>
<body id="top">


<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
    <div class="container">

        
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://tgjeon.github.io/">Taegyun Jeon</a>
        </div>

        
        <div class="collapse navbar-collapse" id="#navbar-collapse-1">

            
            <ul class="nav navbar-nav navbar-right">
                
                <li class="nav-item"><a href="https://tgjeon.github.io/#top">Home</a></li>
                
                <li class="nav-item"><a href="https://tgjeon.github.io/#publications">Publications</a></li>
                
                <li class="nav-item"><a href="https://tgjeon.github.io/#posts">Posts</a></li>
                
                <li class="nav-item"><a href="https://tgjeon.github.io/#projects">Projects</a></li>
                
                <li class="nav-item"><a href="https://tgjeon.github.io/#contact">Contact</a></li>
                
            </ul>

        </div>
    </div>
</nav>

<div class="container">

    <article class="article" itemscope itemtype="http://schema.org/Article">
        <h1 itemprop="name">Recurrent Neural Networks</h1>

        

<div class="article-metadata">

    <span class="article-date">
        <time datetime="2016-07-05 05:33:52 &#43;0900 KST" itemprop="datePublished">Tue, Jul 5, 2016</time>
    </span>

    
    
    
    <span class="article-tags">
        <i class="fa fa-tags"></i>
        
        <a class="article-tag-link" href="https://tgjeon.github.io/tags/deep-learning">Deep Learning</a>, 
        
        <a class="article-tag-link" href="https://tgjeon.github.io/tags/translation">Translation</a>, 
        
        <a class="article-tag-link" href="https://tgjeon.github.io/tags/rnn">RNN</a>
        
    </span>
    
    

    
        
<ul class="share">
    <li>
        <a class="facebook" href="https://www.facebook.com/sharer.php?u=" target="_blank">
            <i class="fa fa-facebook-square"></i>
            <span class="hidden">Facebook</span>
        </a>
    </li>
    <li>
        <a class="twitter" href="https://twitter.com/intent/tweet?text=&amp;url=" target="_blank">
            <i class="fa fa-twitter-square"></i>
            <span class="hidden">Twitter</span>
        </a>
    </li>
    <li>
        <a class="linkedin" href="http://www.linkedin.com/shareArticle?mini=true&amp;url=&amp;title=" target="_blank">
            <i class="fa fa-linkedin-square"></i>
            <span class="hidden">LinkedIn</span>
        </a>
    </li>
    <li>
        <a class="email" href="mailto:?subject=&amp;body=">
            <i class="fa fa-envelope-square"></i>
            <span class="hidden">Email</span>
        </a>
    </li>
</ul>


    

</div>


        <div class="post" itemprop="articleBody">
            

<h3 id="chapter-10-sequence-modeling-recurrent-and-recursive-nets">Chapter 10. Sequence Modeling: Recurrent and Recursive Nets</h3>

<blockquote>
<p><a href="http://www.deeplearningbook.org">Original book chapter</a> is written by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.</p>
</blockquote>

<p>이 포스트는 &ldquo;Deep Learning published by Mit Press (2016)&rdquo; 의 Recurrent Neural Networks에 해당되는 내용을 한글로 정리한 내용입니다. 해당 그림은 저작권 문제로 위 링크를 참고하여 확인하시기 바랍니다.</p>

<hr />

<h3 id="10-2-recurrent-neural-networks-rnns">10.2 Recurrent Neural Networks (RNNs)</h3>

<p>앞선 <a href="https://tgjeon.github.io/post/rnn_unfolding_computational_graph/">포스트</a>에서 설명한 그래프 풀기 (graph unrolling)과 파라미터 공유 (parameter sharing)을 통해 다양한 형태의 recurrent neural networks를 디자인 할 수 있다.</p>

<p>Recurrent Neural Networks의 중요한 디자인 패턴들은 다음과 같다.</p>

<ol>
<li>그림 10.3

<ul>
<li>Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden (hidden unit간 연결)</li>
<li>$(x, h), (h, o), (o, L), (L, y), (h^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)</li>
</ul></li>
<li>그림 10.4

<ul>
<li>Input (매 시점 t 마다), Output (매 시점 t 마다), Hidden-Output (hidden/output unit간 연결)</li>
<li>$(x, h), (h, o), (o, L), (L, y), (o^{t-1}, h^t)$  (여기서 (a, b)는 a와 b가 연결됨을 의미)</li>
</ul></li>
<li>그림 10.5

<ul>
<li>Input (매 시점 t 마다), Output (최종 시점 $\tau$에만), Hidden (hidden unit간 연결)</li>
<li>$(x, h), (h^{\tau}, o^{\tau}), (o^\tau, L^\tau), (L^\tau, y^\tau)$ (여기서 (a, b)는 a와 b가 연결됨을 의미)</li>
</ul></li>
</ol>

<p>처음 소개된 그림 10.3과 같은 형태는, recurrent neural networks의 가장 대표적인 형태이며, 이번 내용에서 가장 많이 설명될 것이다. 이와 같은 형태는 Turing machine과 같은 계산 과정을 통해 수행된다고 생각하면 된다. 시점 $t$의 갯수 (점근적 선형으로 증가하는) 만큼의 입력을 받아 해당 시점 이후의 출력을 가진다. 이는 근사치가 아닌 정확한 계산 결과이며 이산값으로 나타낸다.</p>

<p>그림 10.3에서 동작하는 forward propagation 수식을 살펴보자. 개념적인 이야기를 다루고 있기 때문에, activation function, loss function, output 형태를 언급하지 않고 있다. 따라서, activation function은 $\tanh$로 두고 output은 discrete 값을 가정한다. 그리고 RNN 모델은 단어나 문자를 예측하는데 사용된다고 가정하자.</p>

<ul>
<li>output $o$는 각 이산값에 대해 정규화되지 않은 확률 분포로 나타낸다.</li>
<li>최종 예측값은 $\hat{y}$는 출력 $o$에 대해 softmax()를 적용하여 정규화된 확률 값을 가진다.</li>
</ul>

<p>Forward propagation은 다음과 같이 동작한다.</p>

<ul>
<li>Initial state: $h^{(0)}$로 부터 시작.</li>
<li>Input-to-hidden ($U$)과 hidden-to-hidden ($W$): $a^{(t)} = b + Wh^{(t-1)} + Ux^{(t)}$</li>
<li>Activation: $h^{(t)} = \tanh(a^{(t)})$</li>
<li>hidden-to-output ($V$): $o^{(t)} = c + Vh^{(t)}$</li>
<li>Normailized discrete output: ${\hat{y}}^{(t)} = softmax(o^{(t)})$</li>
</ul>

<p>이 모델은 입력 sequence와 출력 sequence의 길이가 동일하다. 전체 입,출력 sequence에 대한 loss는 각 시점 (time steps)마다의 loss를 모두 더한 것과 같다.</p>

<p>$ L(${ $x^{(1)}, &hellip;, x^{(\tau)} $}, { $y{(1)}, &hellip;, y^{(\tau)} $}$)$</p>

<p>$= \sum _{t}{L^{(t)}} $</p>

<p>$= -\sum _{t}{\log{p}} _{model} (y^{(t)} | ${ $x^{(1)}, &hellip;, x^{(t)} $}$)$</p>

<p>$L^{(t)} $가 입력 $x^{(1)}, &hellip;, x^{(t)}$이 주어졌을 때, 출력 $y^{(t)}$에 대한 negative log-likelihood라고 하자.
gradient를 계산하는 과정은 각 시점 (time steps)에 대해 수행된다. 수행 시간은 $O(\tau)$이며, 병렬처리가 불가능하다.
이 모델은 강력하지만 학습 과정에서 많은 계산량을 요구한다. 이를 <em>back-propagation through time</em> 혹은 <em>BPTT</em> 라고 한다.</p>

<h3 id="10-2-1-teacher-forcing-and-networks-with-output-recurrence">10.2.1 Teacher Forcing and Networks with Output Recurrence</h3>

<p>그림 10.4에서 보여주고 있는 RNN모델은 hidden-to-hidden 연결성이 부족하기 때문에 강력하지 않다. hidden-to-hidden 연결이 없기 때문에, output 유닛이 과거 네트워크의 모든 정보를 가지고 미래를 예측해야한다. 그래서, output 유닛은 명백하게 학습 데이터의 타겟에 대해 학습된다. 사용자는 과거 모든 입력의 기록을 모아둘 필요가 없어진다.</p>

<p>hidden-to-hidden 연결을 제거함으로 얻는 이득은, 시점 $t$에서 예측하는 데 필요한 loss의 계산이 모든 시점 $t$에 대한 관계성이 없어진다. 따라서 학습 단계는 병렬처리 가능하며, 각 시점 $t$에서의 gradient 계산은 독립적으로 수행 가능하다.</p>

<p>output에서 바로 모델이 학습 하는 경우를 teacher forcing 이라고 한다. 이는 maximum likelihood criterion을 따르며, ground truth $\hat(y)^{(t)}$가 $t+1$ 시점의 입력으로 사용된다는 것을 의미한다.</p>

<p>두 시점의 sequence를 예를 들어보면, conditional maximum likelihood criterion은 다음과 같다.</p>

<p>$ \log{p} (y^{(1)}, y^{(2)} | x^{(1)}, x^{(2)})$</p>

<p>$ = \log{p} (y^{(2)} | y^{(1)}, x^{(1)}, x^{(2)})  +  \log{p} (y^{(1)} | x^{(1)}, x^{(2)}) $</p>

        </div>
    </article>

    <nav>
    <ul class="pager">
        
        <li class="previous"><a href="https://tgjeon.github.io/post/stochastic_gradient_methods/"><span aria-hidden="true">&larr;</span> Stochastic Gradient Methods</a></li>
        

        
    </ul>
</nav>

    
<section id="comments">
    <div id="disqus_thread">
        <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'tgjeon';
    var disqus_identifier = 'https:\/\/tgjeon.github.io\/post\/rnn_rnn\/';
    var disqus_title = 'Recurrent Neural Networks';
    var disqus_url = 'https:\/\/tgjeon.github.io\/post\/rnn_rnn\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
</section>



</div>
<footer class="site-footer">
    <div class="container">
        <p class="powered-by">

            &copy; 2016 Taegyun Jeon &middot; 

            Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

            <span class="pull-right"><a href="#" id="back_to_top"><span class="button_icon"><i class="fa fa-chevron-up fa-2x" aria-hidden="true"></i></span></a></span>

        </p>
    </div>
</footer>

        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
        <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
        <script src="https://tgjeon.github.io/js/jquery-1.12.3.min.js"></script>
        <script src="https://tgjeon.github.io/js/bootstrap.min.js"></script>
        <script src="https://tgjeon.github.io/js/hugo-academic.js"></script>
        

        
        <script>
            (function(i,s,o,g,r,a,m){
                i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},
                    i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;
                m.parentNode.insertBefore(a,m)
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
            ga('create', 'UA-77919576-1', 'auto');
            ga('set', 'anonymizeIp', true);
            ga('send', 'pageview');

             
            var links = document.querySelectorAll('a');
            Array.prototype.map.call(links, function(item) {
                if (item.host != document.location.host) {
                    item.addEventListener('click', function() {
                        var action = item.getAttribute('data-action') || 'follow';
                        ga('send', 'event', 'outbound', action, item.href);
                    });
                }
            });
        </script>
        

        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        
        
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
        

    </body>
</html>

